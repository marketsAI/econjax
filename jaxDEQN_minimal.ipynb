{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasCovarrubias/econjax/blob/main/jaxDEQN_minimal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmNe6o_4tTEy"
      },
      "source": [
        "# Deep Equilibrium Nets (DEQN) with Jax\n",
        "\n",
        "This notebook implement the DEQN methodology (Azimovic et al, put link) using JAX. We will start with some imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0dX6Q14A1Q",
        "outputId": "67b9370f-5a4e-4e78-e347-55a5844ea817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "! pip install optax -q\n",
        "! pip install flax -q\n",
        "\n",
        "# Setup TPU (note: this has to run before imports)\n",
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()\n",
        "\n",
        "# Imports\n",
        "import jax\n",
        "from jax import lax\n",
        "from jax import random\n",
        "from jax import numpy as jnp\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, checkpoints\n",
        "import optax\n",
        "import numpy as np\n",
        "import timeit\n",
        "from typing import Sequence\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(jax.devices())\n",
        "\n",
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Gndmjztrul"
      },
      "source": [
        "Structure of the code:\n",
        "0. Import model structures and create policies.\n",
        "  1. [x] Import variance-covariance matrix.\n",
        "  2. [x] Create montecarlo simulator\n",
        "  4. [x] Create neural net policy.\n",
        "  5. [x] Import dynare policy.\n",
        "1. Pre-train Experiment\n",
        "  6. [x] Create pre-train loss function of neural net vs dynare.\n",
        "  7. [x] Create pre-train step function.\n",
        "  8. [x] Create pre-train experiment function.\n",
        "  10. [x] Run pre-train experiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhImo5eJu6RS"
      },
      "source": [
        "## 0. Import model structure and create policies\n",
        "\n",
        "To start, we will import the variance-covariance matrix of the shocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZRV4Rf9u4X9",
        "outputId": "e51c3a21-5be6-42a1-99cf-23e87fd33d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'A', 'B', 'C_IQPL', 'D_IQPL', 'moddel', 'modhwelast', 'modrho', 'modvcv', 'sd_IQPL', 'sd_states', 'ss_IQPL', 'ss_states'])\n",
            "done importing parameteres and dynare state space representation\n"
          ]
        }
      ],
      "source": [
        "# import model parameters\n",
        "import scipy.io as sio\n",
        "matlab_struct = sio.loadmat(\"/content/drive/MyDrive/Jaxecon/ProdNetPert_July16.mat\", simplify_cells = True)\n",
        "print(matlab_struct.keys())\n",
        "\n",
        "\"\"\" Parameteres of the model \"\"\"\n",
        "Sigma_A = jnp.array(matlab_struct[\"modvcv\"])  # variance-covariance of TFP shocks\n",
        "n_sectors = Sigma_A.shape[0]   # number of sectors\n",
        "rho_vec = jnp.array(matlab_struct[\"modrho\"])   # parameter rho\n",
        "dep_vec = jnp.array(matlab_struct[\"moddel\"]) # parameter delta\n",
        "ss_states = jnp.array(matlab_struct[\"ss_states\"]) # steady state of state variables (in logs)\n",
        "ss_IQPL = jnp.array(matlab_struct[\"ss_IQPL\"]) # steady state of policy variables (in logs)\n",
        "\n",
        "\n",
        "\"\"\" Matrices of dynare state-space representation  model \"\"\"\n",
        "A = matlab_struct[\"A\"]  \n",
        "B = matlab_struct[\"B\"] \n",
        "C_IQPL = matlab_struct[\"C_IQPL\"] \n",
        "D_IQPL = matlab_struct[\"D_IQPL\"]\n",
        "\n",
        "\"\"\" Standard deviation of state variables and policy  variables (in logs) \"\"\"\n",
        "sd_states = jnp.array(matlab_struct[\"sd_states\"])\n",
        "sd_IQPL = jnp.array(matlab_struct[\"sd_IQPL\"])\n",
        "\n",
        "print(\"done importing parameteres and dynare state space representation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LXEca1NwAiC"
      },
      "source": [
        "## 1. Pre-train experiment\n",
        "\n",
        "We will start by creating a class that initialize and step forward our economic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "roYc6Stsjrfp"
      },
      "outputs": [],
      "source": [
        "# Environment\n",
        "class ProdNetRbc_pretrain():\n",
        "  \"\"\"A JAX implementation of an RBC model with Production Networks.\"\"\"\n",
        "\n",
        "  def __init__(self, \n",
        "  rho_vec=rho_vec, dep_vec=dep_vec, Sigma_A=Sigma_A, ss_states=ss_states, ss_policy=ss_IQPL, \n",
        "  sd_states=sd_states, A=A, B=B, C=C_IQPL, D=D_IQPL):\n",
        "    self.rho_vec = rho_vec\n",
        "    self.dep_vec = dep_vec\n",
        "    self.n_sectors = rho_vec.shape[0]\n",
        "    self.Sigma_A = Sigma_A\n",
        "    self.ss_states = ss_states\n",
        "    self.ss_policy = ss_policy\n",
        "    self.sd_states = sd_states\n",
        "    self.A = A\n",
        "    self.B = B\n",
        "    self.C = C\n",
        "    self.D = D\n",
        "    self.num_actions = 3*self.n_sectors+1\n",
        "\n",
        "  def initial_state(self, rng):\n",
        "    e = jax.random.multivariate_normal(rng, jnp.zeros((self.n_sectors,)), self.Sigma_A)\n",
        "    state_init = jnp.divide(jnp.dot(self.B,e), self.sd_states)\n",
        "    return lax.stop_gradient(state_init)\n",
        "\n",
        "  def step(self, state, shock): \n",
        "    state_notnorm = jnp.multiply(state, self.sd_states)\n",
        "    new_state_notnorm =jnp.dot(self.A,state_notnorm)+jnp.dot(self.B,shock)\n",
        "    new_state = jnp.divide(new_state_notnorm, self.sd_states)\n",
        "    obs = jnp.concatenate([state[:self.n_sectors], new_state[self.n_sectors:]])\n",
        "    policy_devs = jnp.dot(self.C,state_notnorm)+jnp.dot(self.D,shock)\n",
        "    IQPL = jnp.exp(self.ss_policy+policy_devs)\n",
        "    L_agg = jnp.array([jnp.sum(IQPL[3*self.n_sectors:])])\n",
        "    policy_dynare = jnp.concatenate([IQPL[:3*self.n_sectors],L_agg])\n",
        "    train_pair = (obs, policy_dynare)\n",
        "    return lax.stop_gradient((new_state, train_pair))\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIQLSPJLvaPE"
      },
      "source": [
        "### Create Neural Net policy\n",
        "\n",
        "First, we use Flax to create the Neural Net, Notice that we activate the last layer using Softplus to guarantee that we get possitive outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NVGY1ZCnvtXh"
      },
      "outputs": [],
      "source": [
        "class MLP_softplus(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    for feat in self.features[:-1]:\n",
        "      x = nn.relu(nn.Dense(feat)(x))\n",
        "    x = nn.softplus(nn.Dense(self.features[-1])(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhkvxmxuoBI7"
      },
      "source": [
        "Next, we will create an utility function to Time our throughput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cQpTD7PeoEhn"
      },
      "outputs": [],
      "source": [
        "class TimeIt():\n",
        "\n",
        "  def __init__(self, tag, steps=None):\n",
        "    self.tag = tag\n",
        "    self.steps = steps\n",
        "\n",
        "  def __enter__(self):\n",
        "    self.start = timeit.default_timer()\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *args):\n",
        "    self.elapsed_secs = timeit.default_timer() - self.start\n",
        "    msg = self.tag + (': Elapsed time=%.2fs' % self.elapsed_secs)\n",
        "    if self.steps:\n",
        "      msg += ', FPS=%.2e' % (self.steps / self.elapsed_secs)\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FGm6vTqXqzz"
      },
      "source": [
        "No we define the minimum unit of computation that will bebatched and passed to all the cores of the TPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_learner_fn(\n",
        "    env, nn_forward, opt_update, batch_size, epoque_iters):\n",
        "  \"\"\"It runs and epoque with learing. This is what the compiler reads and parallelize (the minimal unit of computation).\"\"\"\n",
        "  \n",
        "  def traj_loss_fn(nn_params, loss_rng, env_state):\n",
        "    # shocks for the entire trajectory.\n",
        "    shocks = jax.random.multivariate_normal(loss_rng, jnp.zeros((env.n_sectors,)), env.Sigma_A, shape=(batch_size,))\n",
        "    state_final, train_pairs = lax.scan(env.step, env_state, shocks)  # apply period steps for each row shock in shocks.\n",
        "    obs_vector, dynare_policy_vector = train_pairs\n",
        "    nn_policy_vector = nn_forward(nn_params, obs_vector)\n",
        "    traj_abs_loss = jnp.mean(jnp.abs(jnp.divide(nn_policy_vector, dynare_policy_vector)-jnp.ones_like(dynare_policy_vector)))\n",
        "    traj_loss = jnp.mean(jnp.square(jnp.divide(nn_policy_vector, dynare_policy_vector)-jnp.ones_like(dynare_policy_vector)))\n",
        "    \n",
        "    return traj_loss, (state_final, jnp.array([traj_loss]),jnp.array([traj_abs_loss]))\n",
        "\n",
        "  def update_fn(nn_params, opt_state, rng, env_state, mean_loss, mean_abs_loss):\n",
        "    \"\"\"Compute a gradient update from a single trajectory.\"\"\"\n",
        "    rng, loss_rng = random.split(rng)\n",
        "    grads, aux_info  = jax.grad(  # compute gradient on a single trajectory.\n",
        "        traj_loss_fn, has_aux=True)(nn_params, loss_rng, env_state)\n",
        "    new_env_state, mean_loss, mean_abs_loss = aux_info\n",
        "    grads = lax.pmean(grads, axis_name='j')  # reduce mean (average grads) across cores.\n",
        "    grads = lax.pmean(grads, axis_name='i')  # reduce mean (average grads) across batch.\n",
        "    updates, new_opt_state = opt_update(grads, opt_state)  # transform grads.\n",
        "    new_params = optax.apply_updates(nn_params, updates)  # update parameters.\n",
        "    return new_params, new_opt_state, rng, new_env_state, mean_loss, mean_abs_loss\n",
        "\n",
        "  def learner_fn(params, opt_state, rngs, env_states, mean_loss, mean_abs_loss):\n",
        "    \"\"\"Vectorise and repeat the update.\"\"\"\n",
        "    batched_update_fn = jax.vmap(update_fn, axis_name='j')  # vectorize across batch.\n",
        "    def iterate_fn(_, val):  # repeat many times to avoid going back to Python.\n",
        "      params, opt_state, rngs, env_states, mean_loss, mean_abs_loss = val\n",
        "      return batched_update_fn(params, opt_state, rngs, env_states, mean_loss, mean_abs_loss)\n",
        "    return lax.fori_loop(0, epoque_iters, iterate_fn, (\n",
        "        params, opt_state, rngs, env_states, mean_loss, mean_abs_loss))\n",
        "\n",
        "  return learner_fn"
      ],
      "metadata": {
        "id": "zZoQdJ31e7EW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAiCNRxC1AJ"
      },
      "source": [
        "Now we define the learning rate schedule for our experiment:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(env, config):\n",
        "  \"\"\"Runs experiment.\"\"\"\n",
        "  cores_count = len(jax.devices())  # get available TPU cores.\n",
        "  nn_policy = MLP_softplus(config[\"layers\"] + [env.num_actions])\n",
        "  optim = optax.adam(config[\"learning_rate\"])  # define optimiser.\n",
        "\n",
        "  rng, rng_e, rng_p = random.split(random.PRNGKey(config[\"seed\"]), num=3)  # prng keys.\n",
        "  dummy_obs = env.initial_state(rng_e)  # dummy for net init.\n",
        "  params = nn_policy.init(rng_p, dummy_obs)  # initialise params.\n",
        "  nn_forward = nn_policy.apply\n",
        "  mean_loss = jnp.array([0.0]) # initialize loss\n",
        "  mean_abs_loss = jnp.array([0.0]) # initialize loss\n",
        "  opt_state = optim.init(params)  # initialise optimiser stats.\n",
        "  learn = get_learner_fn(env, nn_forward, optim.update, config[\"batch_size\"], config[\"epoque_iters\"])\n",
        "  learn = jax.pmap(learn, axis_name='i')  # replicate over multiple cores.\n",
        "\n",
        "  broadcast = lambda x: jnp.broadcast_to(x, (cores_count, config[\"n_batches\"]) + x.shape)\n",
        "  params = jax.tree_map(broadcast, params)  # broadcast to cores and batch.\n",
        "  opt_state = jax.tree_map(broadcast, opt_state)  # broadcast to cores and batch\n",
        "  mean_loss = jax.tree_map(broadcast, mean_loss)\n",
        "  mean_abs_loss = jax.tree_map(broadcast, mean_abs_loss)\n",
        "\n",
        "  rng, *env_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"]+ 1)\n",
        "  env_states = jax.vmap(env.initial_state)(jnp.stack(env_rngs))  # init envs.\n",
        "  rng, *step_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "  rng, *eval_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "\n",
        "  reshape = lambda x: x.reshape((cores_count, config[\"n_batches\"]) + x.shape[1:])\n",
        "  step_rngs = reshape(jnp.stack(step_rngs))  # add dimension to pmap over.\n",
        "  eval_rngs = reshape(jnp.stack(eval_rngs))  # add dimension to pmap over.\n",
        "  env_states = reshape(env_states)  # add dimension to pmap over.\n",
        "\n",
        "  mean_losses = []\n",
        "  mean_accuracy = []\n",
        "  num_steps = cores_count * config[\"epoque_iters\"] * config[\"batch_size\"] * config[\"n_batches\"]\n",
        "\n",
        "  with TimeIt(tag='COMPILATION'):\n",
        "    learn(params, opt_state, step_rngs, env_states, mean_loss, mean_abs_loss)  # compiles\n",
        "\n",
        "  #First run, we calculate periods per second\n",
        "  with TimeIt(tag='EXECUTION', steps=num_steps):\n",
        "    params, opt_state, step_rngs, env_states, mean_loss, mean_abs_loss = learn(\n",
        "        params, opt_state, step_rngs, env_states, mean_loss, mean_abs_loss)\n",
        "  \n",
        "  #Rest of the runs\n",
        "  for i in range(2,config[\"n_epoques\"]+1):\n",
        "    rng, *step_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "    step_rngs = reshape(jnp.stack(step_rngs))\n",
        "    params, opt_state, step_rngs, env_states, mean_loss, mean_abs_loss = learn( \n",
        "        params, opt_state, step_rngs, env_states, mean_loss, mean_abs_loss) \n",
        "    \n",
        "    mean_losses.append(jnp.mean(mean_loss)) \n",
        "    mean_accuracy.append((1- jnp.mean(mean_abs_loss))*100)\n",
        "      \n",
        "    print('Iteration:', i*config[\"epoque_iters\"], \n",
        "          \", Mean_loss:\", jnp.mean(mean_loss),\n",
        "          \", Learning rate:\", config[\"learning_rate\"](i*config[\"epoque_iters\"]), \n",
        "          \", Mean accuracy (%):\", (1- jnp.mean(mean_abs_loss))*100)\n",
        "    \n",
        "    if i%config[\"reset_env_nepoques\"]==0:\n",
        "      env_states = jnp.zeros_like(env_states)\n",
        "      print(\"ENV RESET\")\n",
        "\n",
        "  # Print best result\n",
        "  print(\"Maximum accuracy attained in training:\", max(mean_accuracy))\n",
        "  \n",
        "  #Checkpoint\n",
        "  checkpoints.save_checkpoint(ckpt_dir=config['working_dir']+config['run_name'], target=params, step=config[\"n_epoques\"]*config[\"epoque_iters\"])\n",
        "\n",
        "  # Plots\n",
        "  plt.plot([i for i in range(len(mean_losses[100:]))], mean_losses[100:])\n",
        "  plt.xlabel('Steps')\n",
        "  plt.ylabel('Mean Losses')\n",
        "  plt.savefig(config['working_dir']+config['run_name']+'/mean_losses.jpg')\n",
        "  plt.close()\n",
        "  \n",
        "  plt.plot([i for i in range(len(mean_accuracy[100:]))], mean_accuracy[100:])\n",
        "  plt.xlabel('Steps')\n",
        "  plt.ylabel('Mean Accuracy')\n",
        "  plt.savefig(config['working_dir']+config['run_name']+'/mean_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        " \n",
        "  return params, optim, nn_policy, mean_losses, mean_accuracy"
      ],
      "metadata": {
        "id": "tw69_Ic-dcVr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlXarixBjTC2"
      },
      "source": [
        "Now we are to configure our experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zWgbr0HjQua",
        "outputId": "da41902c-5586-4de3-de1a-fca8d0565c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters of NN: 1049600\n",
            "periods per episode: 512\n",
            "periods per epoque: 512000\n"
          ]
        }
      ],
      "source": [
        "'''Confg dictionary'''\n",
        "\n",
        "#learning rate schedule (just put the number if you want it fixed)\n",
        "lr_schedule = optax.join_schedules(\n",
        "      schedules= [optax.constant_schedule(0.0001),\n",
        "                  optax.constant_schedule(0.00001),\n",
        "                  optax.constant_schedule(0.000001), \n",
        "                  optax.constant_schedule(0.0000008),\n",
        "                  optax.constant_schedule(0.0000004)],   \n",
        "      boundaries=[200000,400000,600000,800000]\n",
        "      )\n",
        "\n",
        "# Now we create a config dict\n",
        "config = {\n",
        "    \"n_batches\": 1, # number of minibatches per device ( for a total of 8*n_batches batches)\n",
        "    \"batch_size\": 64, # size of each minibatch\n",
        "    \"layers\": [1024,1024], # layers of the NN\n",
        "    \"epoque_iters\": 1000, # frequency at which we print mean loss\n",
        "    \"n_epoques\": 1000, # number of log cycles (4000)\n",
        "    #(if epoque_iters =100, and n_epoques=1000, total iters are 100000)\n",
        "    \"learning_rate\": lr_schedule,\n",
        "    \"seed\": 260, # random seed, set to whatever int.\n",
        "    \"reset_env_nepoques\": 10000,\n",
        "    \"run_name\": \"run_correct_1\",\n",
        "    \"date\": \"August_14\",\n",
        "    \"working_dir\": \"/content/drive/MyDrive/Jaxecon/Pretraining/\"\n",
        "}\n",
        "\n",
        "# Print some key statistics\n",
        "print(\n",
        "    \"Number of parameters of NN:\",\n",
        "    jnp.sum(jnp.array([(config[\"layers\"][i]+1)*config[\"layers\"][i+1] for i in range(len(config[\"layers\"])-1)])))\n",
        "cores_count = len(jax.devices())\n",
        "\n",
        "num_steps_perepisode = cores_count * config[\"batch_size\"] * config[\"n_batches\"]\n",
        "print(\"periods per episode:\", num_steps_perepisode)\n",
        "\n",
        "num_steps_percycle = cores_count * config[\"epoque_iters\"] * config[\"batch_size\"] * config[\"n_batches\"]\n",
        "print(\"periods per epoque:\", num_steps_percycle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awmY1xXgDOcU",
        "outputId": "6814137f-d4e0-4ff0-a7e4-cd3d2de87aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPILATION: Elapsed time=3.75s\n",
            "EXECUTION: Elapsed time=1.11s, FPS=4.62e+05\n",
            "Iteration: 2000 , Mean_loss: 199.01389 , Learning rate: 1e-04 , Mean accuracy (%): -151.08275\n",
            "Iteration: 3000 , Mean_loss: 65.0714 , Learning rate: 1e-04 , Mean accuracy (%): -23.890448\n",
            "Iteration: 4000 , Mean_loss: 39.070595 , Learning rate: 1e-04 , Mean accuracy (%): -7.8557014\n",
            "Iteration: 5000 , Mean_loss: 18.533617 , Learning rate: 1e-04 , Mean accuracy (%): 24.197054\n",
            "Iteration: 6000 , Mean_loss: 5.270056 , Learning rate: 1e-04 , Mean accuracy (%): 40.50026\n",
            "Iteration: 7000 , Mean_loss: 5.1802473 , Learning rate: 1e-04 , Mean accuracy (%): 47.164333\n",
            "Iteration: 8000 , Mean_loss: 3.8416166 , Learning rate: 1e-04 , Mean accuracy (%): 50.331543\n",
            "Iteration: 9000 , Mean_loss: 1.6130803 , Learning rate: 1e-04 , Mean accuracy (%): 54.99593\n",
            "Iteration: 10000 , Mean_loss: 0.85396814 , Learning rate: 1e-04 , Mean accuracy (%): 58.73233\n",
            "Iteration: 11000 , Mean_loss: 0.5460296 , Learning rate: 1e-04 , Mean accuracy (%): 59.47286\n",
            "Iteration: 12000 , Mean_loss: 0.41452768 , Learning rate: 1e-04 , Mean accuracy (%): 61.535095\n",
            "Iteration: 13000 , Mean_loss: 0.46102092 , Learning rate: 1e-04 , Mean accuracy (%): 62.308685\n",
            "Iteration: 14000 , Mean_loss: 0.31454527 , Learning rate: 1e-04 , Mean accuracy (%): 62.780144\n",
            "Iteration: 15000 , Mean_loss: 0.34504294 , Learning rate: 1e-04 , Mean accuracy (%): 62.429893\n",
            "Iteration: 16000 , Mean_loss: 0.36124244 , Learning rate: 1e-04 , Mean accuracy (%): 63.204185\n",
            "Iteration: 17000 , Mean_loss: 0.34046388 , Learning rate: 1e-04 , Mean accuracy (%): 63.932938\n",
            "Iteration: 18000 , Mean_loss: 0.2980206 , Learning rate: 1e-04 , Mean accuracy (%): 64.077934\n",
            "Iteration: 19000 , Mean_loss: 0.4033054 , Learning rate: 1e-04 , Mean accuracy (%): 62.987946\n",
            "Iteration: 20000 , Mean_loss: 0.2995176 , Learning rate: 1e-04 , Mean accuracy (%): 64.073906\n",
            "Iteration: 21000 , Mean_loss: 0.2785266 , Learning rate: 1e-04 , Mean accuracy (%): 66.14525\n",
            "Iteration: 22000 , Mean_loss: 0.2770373 , Learning rate: 1e-04 , Mean accuracy (%): 65.682724\n",
            "Iteration: 23000 , Mean_loss: 0.26581687 , Learning rate: 1e-04 , Mean accuracy (%): 67.87341\n",
            "Iteration: 24000 , Mean_loss: 0.26491266 , Learning rate: 1e-04 , Mean accuracy (%): 67.37184\n",
            "Iteration: 25000 , Mean_loss: 0.3356086 , Learning rate: 1e-04 , Mean accuracy (%): 67.22513\n",
            "Iteration: 26000 , Mean_loss: 0.2507862 , Learning rate: 1e-04 , Mean accuracy (%): 68.82302\n",
            "Iteration: 27000 , Mean_loss: 0.22661474 , Learning rate: 1e-04 , Mean accuracy (%): 70.87368\n",
            "Iteration: 28000 , Mean_loss: 0.26305002 , Learning rate: 1e-04 , Mean accuracy (%): 70.90846\n",
            "Iteration: 29000 , Mean_loss: 0.20983873 , Learning rate: 1e-04 , Mean accuracy (%): 72.57682\n",
            "Iteration: 30000 , Mean_loss: 0.19900763 , Learning rate: 1e-04 , Mean accuracy (%): 74.92549\n",
            "Iteration: 31000 , Mean_loss: 0.16131602 , Learning rate: 1e-04 , Mean accuracy (%): 77.26028\n",
            "Iteration: 32000 , Mean_loss: 0.11244625 , Learning rate: 1e-04 , Mean accuracy (%): 82.38858\n",
            "Iteration: 33000 , Mean_loss: 0.06728162 , Learning rate: 1e-04 , Mean accuracy (%): 86.585625\n",
            "Iteration: 34000 , Mean_loss: 0.04501695 , Learning rate: 1e-04 , Mean accuracy (%): 89.09264\n",
            "Iteration: 35000 , Mean_loss: 0.02796455 , Learning rate: 1e-04 , Mean accuracy (%): 91.46693\n",
            "Iteration: 36000 , Mean_loss: 0.01715711 , Learning rate: 1e-04 , Mean accuracy (%): 93.148224\n",
            "Iteration: 37000 , Mean_loss: 0.011085444 , Learning rate: 1e-04 , Mean accuracy (%): 94.55227\n",
            "Iteration: 38000 , Mean_loss: 0.008908423 , Learning rate: 1e-04 , Mean accuracy (%): 95.023766\n",
            "Iteration: 39000 , Mean_loss: 0.00637798 , Learning rate: 1e-04 , Mean accuracy (%): 95.73689\n",
            "Iteration: 40000 , Mean_loss: 0.0049130437 , Learning rate: 1e-04 , Mean accuracy (%): 96.295\n",
            "Iteration: 41000 , Mean_loss: 0.004093123 , Learning rate: 1e-04 , Mean accuracy (%): 96.568665\n",
            "Iteration: 42000 , Mean_loss: 0.003196185 , Learning rate: 1e-04 , Mean accuracy (%): 96.99367\n",
            "Iteration: 43000 , Mean_loss: 0.0026789762 , Learning rate: 1e-04 , Mean accuracy (%): 97.228455\n",
            "Iteration: 44000 , Mean_loss: 0.0022697053 , Learning rate: 1e-04 , Mean accuracy (%): 97.48596\n",
            "Iteration: 45000 , Mean_loss: 0.0018411377 , Learning rate: 1e-04 , Mean accuracy (%): 97.708755\n",
            "Iteration: 46000 , Mean_loss: 0.0015908431 , Learning rate: 1e-04 , Mean accuracy (%): 97.81556\n",
            "Iteration: 47000 , Mean_loss: 0.0013135867 , Learning rate: 1e-04 , Mean accuracy (%): 98.04266\n",
            "Iteration: 48000 , Mean_loss: 0.0011374307 , Learning rate: 1e-04 , Mean accuracy (%): 98.14694\n",
            "Iteration: 49000 , Mean_loss: 0.0010248123 , Learning rate: 1e-04 , Mean accuracy (%): 98.24846\n",
            "Iteration: 50000 , Mean_loss: 0.00089425547 , Learning rate: 1e-04 , Mean accuracy (%): 98.364136\n",
            "Iteration: 51000 , Mean_loss: 0.0008095199 , Learning rate: 1e-04 , Mean accuracy (%): 98.447014\n",
            "Iteration: 52000 , Mean_loss: 0.0007717021 , Learning rate: 1e-04 , Mean accuracy (%): 98.41272\n",
            "Iteration: 53000 , Mean_loss: 0.0006091971 , Learning rate: 1e-04 , Mean accuracy (%): 98.61942\n",
            "Iteration: 54000 , Mean_loss: 0.00057923363 , Learning rate: 1e-04 , Mean accuracy (%): 98.64702\n",
            "Iteration: 55000 , Mean_loss: 0.00071195257 , Learning rate: 1e-04 , Mean accuracy (%): 98.380974\n",
            "Iteration: 56000 , Mean_loss: 0.00043211825 , Learning rate: 1e-04 , Mean accuracy (%): 98.811455\n",
            "Iteration: 57000 , Mean_loss: 0.0004259525 , Learning rate: 1e-04 , Mean accuracy (%): 98.79089\n",
            "Iteration: 58000 , Mean_loss: 0.0003778176 , Learning rate: 1e-04 , Mean accuracy (%): 98.84826\n",
            "Iteration: 59000 , Mean_loss: 0.00031993055 , Learning rate: 1e-04 , Mean accuracy (%): 98.96065\n",
            "Iteration: 60000 , Mean_loss: 0.00026036828 , Learning rate: 1e-04 , Mean accuracy (%): 99.04541\n",
            "Iteration: 61000 , Mean_loss: 0.0002766677 , Learning rate: 1e-04 , Mean accuracy (%): 99.01054\n",
            "Iteration: 62000 , Mean_loss: 0.00025223 , Learning rate: 1e-04 , Mean accuracy (%): 99.06481\n",
            "Iteration: 63000 , Mean_loss: 0.00019972636 , Learning rate: 1e-04 , Mean accuracy (%): 99.15004\n",
            "Iteration: 64000 , Mean_loss: 0.00018383002 , Learning rate: 1e-04 , Mean accuracy (%): 99.165634\n",
            "Iteration: 65000 , Mean_loss: 0.00016215413 , Learning rate: 1e-04 , Mean accuracy (%): 99.22225\n",
            "Iteration: 66000 , Mean_loss: 0.00014610135 , Learning rate: 1e-04 , Mean accuracy (%): 99.24898\n",
            "Iteration: 67000 , Mean_loss: 0.00014820638 , Learning rate: 1e-04 , Mean accuracy (%): 99.2205\n",
            "Iteration: 68000 , Mean_loss: 0.00011817516 , Learning rate: 1e-04 , Mean accuracy (%): 99.31801\n",
            "Iteration: 69000 , Mean_loss: 0.00011281457 , Learning rate: 1e-04 , Mean accuracy (%): 99.33507\n",
            "Iteration: 70000 , Mean_loss: 0.00010297652 , Learning rate: 1e-04 , Mean accuracy (%): 99.36538\n",
            "Iteration: 71000 , Mean_loss: 9.014721e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.38992\n",
            "Iteration: 72000 , Mean_loss: 9.813975e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.366295\n",
            "Iteration: 73000 , Mean_loss: 9.036655e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.40166\n",
            "Iteration: 74000 , Mean_loss: 8.720079e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.41704\n",
            "Iteration: 75000 , Mean_loss: 8.0064165e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.42406\n",
            "Iteration: 76000 , Mean_loss: 7.1001574e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.44429\n",
            "Iteration: 77000 , Mean_loss: 6.159725e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.49069\n",
            "Iteration: 78000 , Mean_loss: 6.5824344e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.470856\n",
            "Iteration: 79000 , Mean_loss: 6.958723e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.46345\n",
            "Iteration: 80000 , Mean_loss: 5.0018512e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.54749\n",
            "Iteration: 81000 , Mean_loss: 5.3868698e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.541756\n",
            "Iteration: 82000 , Mean_loss: 4.117788e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.58355\n",
            "Iteration: 83000 , Mean_loss: 4.727717e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.54416\n",
            "Iteration: 84000 , Mean_loss: 3.759904e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.58847\n",
            "Iteration: 85000 , Mean_loss: 3.4991746e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.5989\n",
            "Iteration: 86000 , Mean_loss: 6.322201e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.47203\n",
            "Iteration: 87000 , Mean_loss: 0.000114450115 , Learning rate: 1e-04 , Mean accuracy (%): 99.27048\n",
            "Iteration: 88000 , Mean_loss: 4.353436e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.56892\n",
            "Iteration: 89000 , Mean_loss: 3.9528568e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.58549\n",
            "Iteration: 90000 , Mean_loss: 2.8225659e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.64917\n",
            "Iteration: 91000 , Mean_loss: 3.2061616e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.6329\n",
            "Iteration: 92000 , Mean_loss: 6.054868e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.46151\n",
            "Iteration: 93000 , Mean_loss: 5.3325515e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.517944\n",
            "Iteration: 94000 , Mean_loss: 3.8706585e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.588356\n",
            "Iteration: 95000 , Mean_loss: 0.00014118581 , Learning rate: 1e-04 , Mean accuracy (%): 99.22638\n",
            "Iteration: 96000 , Mean_loss: 2.3107688e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.67917\n",
            "Iteration: 97000 , Mean_loss: 3.4721495e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.61859\n",
            "Iteration: 98000 , Mean_loss: 2.5968355e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.661644\n",
            "Iteration: 99000 , Mean_loss: 2.44964e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.670235\n",
            "Iteration: 100000 , Mean_loss: 2.1940063e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.70177\n",
            "Iteration: 101000 , Mean_loss: 2.8442264e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.62176\n",
            "Iteration: 102000 , Mean_loss: 3.6643673e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.61644\n",
            "Iteration: 103000 , Mean_loss: 2.425098e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.67082\n",
            "Iteration: 104000 , Mean_loss: 2.2017046e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.68791\n",
            "Iteration: 105000 , Mean_loss: 0.00014467168 , Learning rate: 1e-04 , Mean accuracy (%): 99.16711\n",
            "Iteration: 106000 , Mean_loss: 3.5282577e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.626366\n",
            "Iteration: 107000 , Mean_loss: 1.7784581e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.72712\n",
            "Iteration: 108000 , Mean_loss: 1.9630403e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.70001\n",
            "Iteration: 109000 , Mean_loss: 2.3318835e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.672585\n",
            "Iteration: 110000 , Mean_loss: 1.6910068e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.721725\n",
            "Iteration: 111000 , Mean_loss: 2.5903515e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.68031\n",
            "Iteration: 112000 , Mean_loss: 6.7894696e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.46656\n",
            "Iteration: 113000 , Mean_loss: 2.7733113e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.67015\n",
            "Iteration: 114000 , Mean_loss: 3.6840218e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.61285\n",
            "Iteration: 115000 , Mean_loss: 5.8869347e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.4805\n",
            "Iteration: 116000 , Mean_loss: 1.7179493e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.72638\n",
            "Iteration: 117000 , Mean_loss: 3.371434e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.65421\n",
            "Iteration: 118000 , Mean_loss: 4.6234843e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.57401\n",
            "Iteration: 119000 , Mean_loss: 1.7090519e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.73746\n",
            "Iteration: 120000 , Mean_loss: 1.560117e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.740425\n",
            "Iteration: 121000 , Mean_loss: 2.0331978e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.70885\n",
            "Iteration: 122000 , Mean_loss: 1.4401547e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.74807\n",
            "Iteration: 123000 , Mean_loss: 1.6490574e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.72995\n",
            "Iteration: 124000 , Mean_loss: 4.2463194e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.61272\n",
            "Iteration: 125000 , Mean_loss: 1.3184552e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.767944\n",
            "Iteration: 126000 , Mean_loss: 1.2448181e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.77554\n",
            "Iteration: 127000 , Mean_loss: 1.6425467e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.74959\n",
            "Iteration: 128000 , Mean_loss: 2.6886382e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.66376\n",
            "Iteration: 129000 , Mean_loss: 2.7347085e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.68787\n",
            "Iteration: 130000 , Mean_loss: 2.039468e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.70679\n",
            "Iteration: 131000 , Mean_loss: 1.5882997e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.75302\n",
            "Iteration: 132000 , Mean_loss: 5.385478e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.52737\n",
            "Iteration: 133000 , Mean_loss: 2.6753985e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.66708\n",
            "Iteration: 134000 , Mean_loss: 1.8416553e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.72015\n",
            "Iteration: 135000 , Mean_loss: 2.074058e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.726715\n",
            "Iteration: 136000 , Mean_loss: 1.1922372e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.77998\n",
            "Iteration: 137000 , Mean_loss: 8.6294465e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.396324\n",
            "Iteration: 138000 , Mean_loss: 1.5277437e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.74785\n",
            "Iteration: 139000 , Mean_loss: 1.6828091e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.73023\n",
            "Iteration: 140000 , Mean_loss: 1.4695286e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.756714\n",
            "Iteration: 141000 , Mean_loss: 1.0508622e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.79311\n",
            "Iteration: 142000 , Mean_loss: 1.5997868e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.75414\n",
            "Iteration: 143000 , Mean_loss: 1.6250844e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.741165\n",
            "Iteration: 144000 , Mean_loss: 3.5163408e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.6368\n",
            "Iteration: 145000 , Mean_loss: 1.485946e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.75984\n",
            "Iteration: 146000 , Mean_loss: 0.00012230645 , Learning rate: 1e-04 , Mean accuracy (%): 99.23309\n",
            "Iteration: 147000 , Mean_loss: 4.874974e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.561676\n",
            "Iteration: 148000 , Mean_loss: 1.0367767e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.79493\n",
            "Iteration: 149000 , Mean_loss: 2.074814e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.70331\n",
            "Iteration: 150000 , Mean_loss: 1.7589236e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.73489\n",
            "Iteration: 151000 , Mean_loss: 2.1592201e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.700836\n",
            "Iteration: 152000 , Mean_loss: 1.891241e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.74445\n",
            "Iteration: 153000 , Mean_loss: 8.2695144e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.40533\n",
            "Iteration: 154000 , Mean_loss: 1.2541364e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.76503\n",
            "Iteration: 155000 , Mean_loss: 1.3850994e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.76756\n",
            "Iteration: 156000 , Mean_loss: 1.3691699e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.77462\n",
            "Iteration: 157000 , Mean_loss: 1.1926024e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.777916\n",
            "Iteration: 158000 , Mean_loss: 1.1231681e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.78364\n",
            "Iteration: 159000 , Mean_loss: 1.3520345e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.76114\n",
            "Iteration: 160000 , Mean_loss: 1.854085e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.71326\n",
            "Iteration: 161000 , Mean_loss: 1.4262906e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.77368\n",
            "Iteration: 162000 , Mean_loss: 1.3927877e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.76787\n",
            "Iteration: 163000 , Mean_loss: 1.2464749e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.76598\n",
            "Iteration: 164000 , Mean_loss: 1.2730317e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.77488\n",
            "Iteration: 165000 , Mean_loss: 1.5372367e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.72904\n",
            "Iteration: 166000 , Mean_loss: 2.1136304e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.71377\n",
            "Iteration: 167000 , Mean_loss: 1.6153936e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.75413\n",
            "Iteration: 168000 , Mean_loss: 1.2065075e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.780945\n",
            "Iteration: 169000 , Mean_loss: 1.8253004e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.73046\n",
            "Iteration: 170000 , Mean_loss: 1.3083345e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.7747\n",
            "Iteration: 171000 , Mean_loss: 1.3731433e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.74389\n",
            "Iteration: 172000 , Mean_loss: 1.3110979e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.77225\n",
            "Iteration: 173000 , Mean_loss: 1.4070241e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.755356\n",
            "Iteration: 174000 , Mean_loss: 3.057451e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.66177\n",
            "Iteration: 175000 , Mean_loss: 2.204057e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.7034\n",
            "Iteration: 176000 , Mean_loss: 1.2140141e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.779305\n",
            "Iteration: 177000 , Mean_loss: 1.5035568e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.75403\n",
            "Iteration: 178000 , Mean_loss: 1.1175753e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.78421\n",
            "Iteration: 179000 , Mean_loss: 5.2561252e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.54296\n",
            "Iteration: 180000 , Mean_loss: 1.4163631e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.774284\n",
            "Iteration: 181000 , Mean_loss: 1.588129e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.728546\n",
            "Iteration: 182000 , Mean_loss: 1.578267e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.74391\n",
            "Iteration: 183000 , Mean_loss: 1.0823303e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.79062\n",
            "Iteration: 184000 , Mean_loss: 1.51614095e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.75306\n",
            "Iteration: 185000 , Mean_loss: 1.3221284e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.76804\n",
            "Iteration: 186000 , Mean_loss: 6.0260078e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.552605\n",
            "Iteration: 187000 , Mean_loss: 8.80601e-06 , Learning rate: 1e-04 , Mean accuracy (%): 99.8165\n",
            "Iteration: 188000 , Mean_loss: 1.0227279e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.79015\n",
            "Iteration: 189000 , Mean_loss: 1.0527175e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.787605\n",
            "Iteration: 190000 , Mean_loss: 3.219638e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.61224\n",
            "Iteration: 191000 , Mean_loss: 1.1485146e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.78415\n",
            "Iteration: 192000 , Mean_loss: 1.5056045e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.767784\n",
            "Iteration: 193000 , Mean_loss: 1.4143745e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.7538\n",
            "Iteration: 194000 , Mean_loss: 1.0798299e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.79109\n",
            "Iteration: 195000 , Mean_loss: 1.1735454e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.778076\n",
            "Iteration: 196000 , Mean_loss: 1.2449636e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.768394\n",
            "Iteration: 197000 , Mean_loss: 1.398817e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.75933\n",
            "Iteration: 198000 , Mean_loss: 7.576341e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.4347\n",
            "Iteration: 199000 , Mean_loss: 1.4318517e-05 , Learning rate: 1e-04 , Mean accuracy (%): 99.770004\n",
            "Iteration: 200000 , Mean_loss: 3.6983976e-05 , Learning rate: 1e-05 , Mean accuracy (%): 99.630264\n",
            "Iteration: 201000 , Mean_loss: 6.764194e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84491\n",
            "Iteration: 202000 , Mean_loss: 6.998723e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84268\n",
            "Iteration: 203000 , Mean_loss: 6.552344e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84709\n",
            "Iteration: 204000 , Mean_loss: 7.007529e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83882\n",
            "Iteration: 205000 , Mean_loss: 7.1838413e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.839195\n",
            "Iteration: 206000 , Mean_loss: 9.478215e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.81344\n",
            "Iteration: 207000 , Mean_loss: 7.528566e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83593\n",
            "Iteration: 208000 , Mean_loss: 7.86971e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8348\n",
            "Iteration: 209000 , Mean_loss: 7.4855916e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.838104\n",
            "Iteration: 210000 , Mean_loss: 6.843627e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84506\n",
            "Iteration: 211000 , Mean_loss: 7.4656264e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83675\n",
            "Iteration: 212000 , Mean_loss: 7.1769814e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.839264\n",
            "Iteration: 213000 , Mean_loss: 8.08728e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83293\n",
            "Iteration: 214000 , Mean_loss: 6.959137e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8429\n",
            "Iteration: 215000 , Mean_loss: 6.824101e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84434\n",
            "Iteration: 216000 , Mean_loss: 6.9027533e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.844\n",
            "Iteration: 217000 , Mean_loss: 7.351072e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84007\n",
            "Iteration: 218000 , Mean_loss: 7.527212e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.837845\n",
            "Iteration: 219000 , Mean_loss: 7.0458464e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.843475\n",
            "Iteration: 220000 , Mean_loss: 8.172691e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83068\n",
            "Iteration: 221000 , Mean_loss: 7.1259688e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84159\n",
            "Iteration: 222000 , Mean_loss: 7.41417e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.840096\n",
            "Iteration: 223000 , Mean_loss: 7.905013e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83566\n",
            "Iteration: 224000 , Mean_loss: 7.277783e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84042\n",
            "Iteration: 225000 , Mean_loss: 6.9275284e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83998\n",
            "Iteration: 226000 , Mean_loss: 6.4624483e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84674\n",
            "Iteration: 227000 , Mean_loss: 7.638834e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83837\n",
            "Iteration: 228000 , Mean_loss: 7.420019e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83986\n",
            "Iteration: 229000 , Mean_loss: 7.5725475e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.833115\n",
            "Iteration: 230000 , Mean_loss: 7.005674e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.838455\n",
            "Iteration: 231000 , Mean_loss: 7.2716384e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8419\n",
            "Iteration: 232000 , Mean_loss: 8.023131e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.832954\n",
            "Iteration: 233000 , Mean_loss: 6.6314233e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84491\n",
            "Iteration: 234000 , Mean_loss: 6.5310396e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84342\n",
            "Iteration: 235000 , Mean_loss: 7.4969103e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83637\n",
            "Iteration: 236000 , Mean_loss: 6.668133e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84752\n",
            "Iteration: 237000 , Mean_loss: 6.8492477e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84559\n",
            "Iteration: 238000 , Mean_loss: 8.063105e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83446\n",
            "Iteration: 239000 , Mean_loss: 7.0473016e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84218\n",
            "Iteration: 240000 , Mean_loss: 7.5226735e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.836555\n",
            "Iteration: 241000 , Mean_loss: 6.6428656e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.842384\n",
            "Iteration: 242000 , Mean_loss: 7.5580087e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83666\n",
            "Iteration: 243000 , Mean_loss: 7.053027e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84417\n",
            "Iteration: 244000 , Mean_loss: 7.6001024e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83408\n",
            "Iteration: 245000 , Mean_loss: 6.5313156e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.849335\n",
            "Iteration: 246000 , Mean_loss: 7.699464e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.834175\n",
            "Iteration: 247000 , Mean_loss: 8.430848e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.828606\n",
            "Iteration: 248000 , Mean_loss: 9.418682e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.81449\n",
            "Iteration: 249000 , Mean_loss: 6.9529815e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84515\n",
            "Iteration: 250000 , Mean_loss: 6.769942e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84644\n",
            "Iteration: 251000 , Mean_loss: 6.658084e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84607\n",
            "Iteration: 252000 , Mean_loss: 7.6763645e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83688\n",
            "Iteration: 253000 , Mean_loss: 7.658834e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83353\n",
            "Iteration: 254000 , Mean_loss: 6.9216303e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84445\n",
            "Iteration: 255000 , Mean_loss: 6.7346427e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84461\n",
            "Iteration: 256000 , Mean_loss: 7.4795876e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84083\n",
            "Iteration: 257000 , Mean_loss: 7.970859e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83555\n",
            "Iteration: 258000 , Mean_loss: 7.655459e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83482\n",
            "Iteration: 259000 , Mean_loss: 8.3305995e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8296\n",
            "Iteration: 260000 , Mean_loss: 7.026564e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84286\n",
            "Iteration: 261000 , Mean_loss: 7.1501227e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.841125\n",
            "Iteration: 262000 , Mean_loss: 6.630507e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84809\n",
            "Iteration: 263000 , Mean_loss: 8.279738e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.82569\n",
            "Iteration: 264000 , Mean_loss: 7.0699007e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84117\n",
            "Iteration: 265000 , Mean_loss: 7.5440703e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84114\n",
            "Iteration: 266000 , Mean_loss: 8.310499e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83378\n",
            "Iteration: 267000 , Mean_loss: 7.780626e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.836006\n",
            "Iteration: 268000 , Mean_loss: 7.44098e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84182\n",
            "Iteration: 269000 , Mean_loss: 7.132141e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.841866\n",
            "Iteration: 270000 , Mean_loss: 8.609968e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83014\n",
            "Iteration: 271000 , Mean_loss: 6.799256e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84422\n",
            "Iteration: 272000 , Mean_loss: 8.421988e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.82985\n",
            "Iteration: 273000 , Mean_loss: 7.34122e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84051\n",
            "Iteration: 274000 , Mean_loss: 8.995801e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.82603\n",
            "Iteration: 275000 , Mean_loss: 8.078505e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83306\n",
            "Iteration: 276000 , Mean_loss: 6.839209e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8458\n",
            "Iteration: 277000 , Mean_loss: 6.8048257e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84667\n",
            "Iteration: 278000 , Mean_loss: 7.7681725e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83581\n",
            "Iteration: 279000 , Mean_loss: 6.765871e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84698\n",
            "Iteration: 280000 , Mean_loss: 7.228591e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84039\n",
            "Iteration: 281000 , Mean_loss: 7.4423365e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83508\n",
            "Iteration: 282000 , Mean_loss: 7.881388e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.836945\n",
            "Iteration: 283000 , Mean_loss: 8.232052e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8342\n",
            "Iteration: 284000 , Mean_loss: 7.982568e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83396\n",
            "Iteration: 285000 , Mean_loss: 7.223316e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84362\n",
            "Iteration: 286000 , Mean_loss: 7.4461977e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83911\n",
            "Iteration: 287000 , Mean_loss: 7.6094807e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83987\n",
            "Iteration: 288000 , Mean_loss: 6.505293e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84796\n",
            "Iteration: 289000 , Mean_loss: 8.643423e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.82612\n",
            "Iteration: 290000 , Mean_loss: 7.5362404e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83893\n",
            "Iteration: 291000 , Mean_loss: 8.127532e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.834724\n",
            "Iteration: 292000 , Mean_loss: 6.863809e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84625\n",
            "Iteration: 293000 , Mean_loss: 6.938214e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84252\n",
            "Iteration: 294000 , Mean_loss: 7.591038e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83661\n",
            "Iteration: 295000 , Mean_loss: 7.5705516e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83879\n",
            "Iteration: 296000 , Mean_loss: 6.690885e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84789\n",
            "Iteration: 297000 , Mean_loss: 7.005669e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84476\n",
            "Iteration: 298000 , Mean_loss: 6.1956816e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85349\n",
            "Iteration: 299000 , Mean_loss: 7.673034e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8336\n",
            "Iteration: 300000 , Mean_loss: 6.889257e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.845436\n",
            "Iteration: 301000 , Mean_loss: 6.3774373e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85158\n",
            "Iteration: 302000 , Mean_loss: 6.9889993e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84601\n",
            "Iteration: 303000 , Mean_loss: 6.4102724e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.851\n",
            "Iteration: 304000 , Mean_loss: 7.331713e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.837265\n",
            "Iteration: 305000 , Mean_loss: 6.142167e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85279\n",
            "Iteration: 306000 , Mean_loss: 7.268815e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84281\n",
            "Iteration: 307000 , Mean_loss: 6.4000506e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8512\n",
            "Iteration: 308000 , Mean_loss: 6.864717e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84664\n",
            "Iteration: 309000 , Mean_loss: 6.5226136e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8461\n",
            "Iteration: 310000 , Mean_loss: 7.5903126e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83841\n",
            "Iteration: 311000 , Mean_loss: 7.0689193e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.841484\n",
            "Iteration: 312000 , Mean_loss: 7.527562e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.836334\n",
            "Iteration: 313000 , Mean_loss: 7.456905e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83751\n",
            "Iteration: 314000 , Mean_loss: 6.6088232e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84812\n",
            "Iteration: 315000 , Mean_loss: 8.282061e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83689\n",
            "Iteration: 316000 , Mean_loss: 6.1370647e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85329\n",
            "Iteration: 317000 , Mean_loss: 6.818287e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84732\n",
            "Iteration: 318000 , Mean_loss: 6.2788004e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.853874\n",
            "Iteration: 319000 , Mean_loss: 6.269254e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85204\n",
            "Iteration: 320000 , Mean_loss: 6.8602094e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.845795\n",
            "Iteration: 321000 , Mean_loss: 7.1256854e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84036\n",
            "Iteration: 322000 , Mean_loss: 7.3629453e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.840614\n",
            "Iteration: 323000 , Mean_loss: 6.616796e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.847694\n",
            "Iteration: 324000 , Mean_loss: 6.6873663e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84901\n",
            "Iteration: 325000 , Mean_loss: 7.1222003e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8449\n",
            "Iteration: 326000 , Mean_loss: 6.6420807e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84824\n",
            "Iteration: 327000 , Mean_loss: 6.160692e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85355\n",
            "Iteration: 328000 , Mean_loss: 8.449323e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.826256\n",
            "Iteration: 329000 , Mean_loss: 6.6158314e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.851715\n",
            "Iteration: 330000 , Mean_loss: 6.381083e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85025\n",
            "Iteration: 331000 , Mean_loss: 6.563425e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84627\n",
            "Iteration: 332000 , Mean_loss: 6.1263136e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85678\n",
            "Iteration: 333000 , Mean_loss: 6.2448844e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85233\n",
            "Iteration: 334000 , Mean_loss: 6.5119343e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84982\n",
            "Iteration: 335000 , Mean_loss: 7.5828193e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83776\n",
            "Iteration: 336000 , Mean_loss: 7.1190234e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.844124\n",
            "Iteration: 337000 , Mean_loss: 6.0911875e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.851105\n",
            "Iteration: 338000 , Mean_loss: 6.664296e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.851166\n",
            "Iteration: 339000 , Mean_loss: 7.106391e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84773\n",
            "Iteration: 340000 , Mean_loss: 1.75551e-05 , Learning rate: 1e-05 , Mean accuracy (%): 99.83775\n",
            "Iteration: 341000 , Mean_loss: 6.4795777e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84999\n",
            "Iteration: 342000 , Mean_loss: 6.3362004e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85194\n",
            "Iteration: 343000 , Mean_loss: 6.448332e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8505\n",
            "Iteration: 344000 , Mean_loss: 5.804498e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85731\n",
            "Iteration: 345000 , Mean_loss: 6.8548334e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84495\n",
            "Iteration: 346000 , Mean_loss: 7.330525e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84394\n",
            "Iteration: 347000 , Mean_loss: 6.6701214e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85156\n",
            "Iteration: 348000 , Mean_loss: 7.977162e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.837585\n",
            "Iteration: 349000 , Mean_loss: 7.064301e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84371\n",
            "Iteration: 350000 , Mean_loss: 6.1641967e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.852455\n",
            "Iteration: 351000 , Mean_loss: 5.8331125e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.856674\n",
            "Iteration: 352000 , Mean_loss: 6.6232164e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85059\n",
            "Iteration: 353000 , Mean_loss: 6.425814e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85152\n",
            "Iteration: 354000 , Mean_loss: 7.4344234e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83987\n",
            "Iteration: 355000 , Mean_loss: 6.308069e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85407\n",
            "Iteration: 356000 , Mean_loss: 7.1983204e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84417\n",
            "Iteration: 357000 , Mean_loss: 6.6605053e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85291\n",
            "Iteration: 358000 , Mean_loss: 6.3279494e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85244\n",
            "Iteration: 359000 , Mean_loss: 6.307257e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85397\n",
            "Iteration: 360000 , Mean_loss: 6.7043848e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85052\n",
            "Iteration: 361000 , Mean_loss: 7.0145343e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84552\n",
            "Iteration: 362000 , Mean_loss: 5.6986523e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.857834\n",
            "Iteration: 363000 , Mean_loss: 6.9503058e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84699\n",
            "Iteration: 364000 , Mean_loss: 7.2531684e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84289\n",
            "Iteration: 365000 , Mean_loss: 6.8437807e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84819\n",
            "Iteration: 366000 , Mean_loss: 6.9597736e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85158\n",
            "Iteration: 367000 , Mean_loss: 6.592094e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85078\n",
            "Iteration: 368000 , Mean_loss: 7.583457e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83753\n",
            "Iteration: 369000 , Mean_loss: 6.065592e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.853264\n",
            "Iteration: 370000 , Mean_loss: 7.942316e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84358\n",
            "Iteration: 371000 , Mean_loss: 6.1333235e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.853775\n",
            "Iteration: 372000 , Mean_loss: 6.7779292e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8486\n",
            "Iteration: 373000 , Mean_loss: 6.4878045e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84991\n",
            "Iteration: 374000 , Mean_loss: 6.9026205e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8461\n",
            "Iteration: 375000 , Mean_loss: 6.36173e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84988\n",
            "Iteration: 376000 , Mean_loss: 6.6104467e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84772\n",
            "Iteration: 377000 , Mean_loss: 7.1654194e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.83651\n",
            "Iteration: 378000 , Mean_loss: 6.8468926e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84792\n",
            "Iteration: 379000 , Mean_loss: 7.024333e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85012\n",
            "Iteration: 380000 , Mean_loss: 5.942924e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85528\n",
            "Iteration: 381000 , Mean_loss: 7.09081e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.846596\n",
            "Iteration: 382000 , Mean_loss: 6.112131e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.8527\n",
            "Iteration: 383000 , Mean_loss: 6.6229404e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84824\n",
            "Iteration: 384000 , Mean_loss: 6.4471856e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85091\n",
            "Iteration: 385000 , Mean_loss: 6.8755467e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84705\n",
            "Iteration: 386000 , Mean_loss: 6.175301e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.854744\n",
            "Iteration: 387000 , Mean_loss: 6.4707456e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84909\n",
            "Iteration: 388000 , Mean_loss: 6.6215225e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84842\n",
            "Iteration: 389000 , Mean_loss: 6.5054105e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84886\n",
            "Iteration: 390000 , Mean_loss: 7.3650544e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.847725\n",
            "Iteration: 391000 , Mean_loss: 6.5358363e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.852264\n",
            "Iteration: 392000 , Mean_loss: 6.7504175e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.848274\n",
            "Iteration: 393000 , Mean_loss: 6.287339e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85341\n",
            "Iteration: 394000 , Mean_loss: 6.520715e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.84738\n",
            "Iteration: 395000 , Mean_loss: 6.5036133e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.847694\n",
            "Iteration: 396000 , Mean_loss: 6.265059e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85353\n",
            "Iteration: 397000 , Mean_loss: 6.140142e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85426\n",
            "Iteration: 398000 , Mean_loss: 6.2090044e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.85391\n",
            "Iteration: 399000 , Mean_loss: 6.544594e-06 , Learning rate: 1e-05 , Mean accuracy (%): 99.853905\n",
            "Iteration: 400000 , Mean_loss: 6.6685225e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.844185\n",
            "Iteration: 401000 , Mean_loss: 5.887803e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86007\n",
            "Iteration: 402000 , Mean_loss: 5.961623e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86036\n",
            "Iteration: 403000 , Mean_loss: 6.516876e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85658\n",
            "Iteration: 404000 , Mean_loss: 6.297955e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.857574\n",
            "Iteration: 405000 , Mean_loss: 5.763212e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86275\n",
            "Iteration: 406000 , Mean_loss: 6.225439e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8579\n",
            "Iteration: 407000 , Mean_loss: 6.73757e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85316\n",
            "Iteration: 408000 , Mean_loss: 5.8496544e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.860466\n",
            "Iteration: 409000 , Mean_loss: 5.914382e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85974\n",
            "Iteration: 410000 , Mean_loss: 5.778803e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.862495\n",
            "Iteration: 411000 , Mean_loss: 5.5233386e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86387\n",
            "Iteration: 412000 , Mean_loss: 5.7207044e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86162\n",
            "Iteration: 413000 , Mean_loss: 6.185319e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.858185\n",
            "Iteration: 414000 , Mean_loss: 5.57513e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.864006\n",
            "Iteration: 415000 , Mean_loss: 6.442068e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85546\n",
            "Iteration: 416000 , Mean_loss: 5.4425072e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86378\n",
            "Iteration: 417000 , Mean_loss: 5.638758e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86154\n",
            "Iteration: 418000 , Mean_loss: 6.440684e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85639\n",
            "Iteration: 419000 , Mean_loss: 6.201254e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.858574\n",
            "Iteration: 420000 , Mean_loss: 5.688209e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86154\n",
            "Iteration: 421000 , Mean_loss: 6.274143e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8571\n",
            "Iteration: 422000 , Mean_loss: 5.5935297e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86302\n",
            "Iteration: 423000 , Mean_loss: 6.3096536e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.856445\n",
            "Iteration: 424000 , Mean_loss: 5.8925034e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8622\n",
            "Iteration: 425000 , Mean_loss: 6.5054014e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85443\n",
            "Iteration: 426000 , Mean_loss: 5.274825e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.867386\n",
            "Iteration: 427000 , Mean_loss: 6.0255984e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85919\n",
            "Iteration: 428000 , Mean_loss: 6.000465e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85901\n",
            "Iteration: 429000 , Mean_loss: 6.6044854e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85251\n",
            "Iteration: 430000 , Mean_loss: 6.1684714e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8578\n",
            "Iteration: 431000 , Mean_loss: 5.980678e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85859\n",
            "Iteration: 432000 , Mean_loss: 6.092233e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85939\n",
            "Iteration: 433000 , Mean_loss: 5.845105e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85966\n",
            "Iteration: 434000 , Mean_loss: 5.8228206e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.861015\n",
            "Iteration: 435000 , Mean_loss: 6.544493e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.855095\n",
            "Iteration: 436000 , Mean_loss: 6.1089104e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85996\n",
            "Iteration: 437000 , Mean_loss: 6.213304e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85748\n",
            "Iteration: 438000 , Mean_loss: 6.713631e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85083\n",
            "Iteration: 439000 , Mean_loss: 6.1547644e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85778\n",
            "Iteration: 440000 , Mean_loss: 5.6443932e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.862465\n",
            "Iteration: 441000 , Mean_loss: 6.4594064e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85519\n",
            "Iteration: 442000 , Mean_loss: 6.760485e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85329\n",
            "Iteration: 443000 , Mean_loss: 5.511636e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86424\n",
            "Iteration: 444000 , Mean_loss: 5.8006904e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86127\n",
            "Iteration: 445000 , Mean_loss: 5.759801e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86124\n",
            "Iteration: 446000 , Mean_loss: 6.2122276e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8577\n",
            "Iteration: 447000 , Mean_loss: 5.8317214e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86048\n",
            "Iteration: 448000 , Mean_loss: 6.491332e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85495\n",
            "Iteration: 449000 , Mean_loss: 6.019017e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85955\n",
            "Iteration: 450000 , Mean_loss: 6.990711e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85238\n",
            "Iteration: 451000 , Mean_loss: 6.3258926e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.855934\n",
            "Iteration: 452000 , Mean_loss: 5.9364966e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85915\n",
            "Iteration: 453000 , Mean_loss: 5.7427555e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.861664\n",
            "Iteration: 454000 , Mean_loss: 6.5635386e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.855095\n",
            "Iteration: 455000 , Mean_loss: 6.376702e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85527\n",
            "Iteration: 456000 , Mean_loss: 6.531374e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.854774\n",
            "Iteration: 457000 , Mean_loss: 6.205284e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85792\n",
            "Iteration: 458000 , Mean_loss: 6.521759e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8562\n",
            "Iteration: 459000 , Mean_loss: 5.958387e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86004\n",
            "Iteration: 460000 , Mean_loss: 6.2531794e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85707\n",
            "Iteration: 461000 , Mean_loss: 5.505758e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.864815\n",
            "Iteration: 462000 , Mean_loss: 6.640743e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85237\n",
            "Iteration: 463000 , Mean_loss: 6.136346e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85901\n",
            "Iteration: 464000 , Mean_loss: 6.811311e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85263\n",
            "Iteration: 465000 , Mean_loss: 6.924158e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.850914\n",
            "Iteration: 466000 , Mean_loss: 5.6241247e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86342\n",
            "Iteration: 467000 , Mean_loss: 6.097213e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85883\n",
            "Iteration: 468000 , Mean_loss: 5.769385e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.862366\n",
            "Iteration: 469000 , Mean_loss: 6.4774194e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85489\n",
            "Iteration: 470000 , Mean_loss: 6.477596e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8548\n",
            "Iteration: 471000 , Mean_loss: 6.911914e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85102\n",
            "Iteration: 472000 , Mean_loss: 5.807856e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86109\n",
            "Iteration: 473000 , Mean_loss: 6.0588454e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85866\n",
            "Iteration: 474000 , Mean_loss: 6.532756e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85345\n",
            "Iteration: 475000 , Mean_loss: 6.0870866e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.858406\n",
            "Iteration: 476000 , Mean_loss: 6.4512233e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85615\n",
            "Iteration: 477000 , Mean_loss: 6.701503e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85102\n",
            "Iteration: 478000 , Mean_loss: 6.4573014e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85663\n",
            "Iteration: 479000 , Mean_loss: 6.0270186e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85856\n",
            "Iteration: 480000 , Mean_loss: 6.455025e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.853714\n",
            "Iteration: 481000 , Mean_loss: 6.242693e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85579\n",
            "Iteration: 482000 , Mean_loss: 6.6191315e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.853584\n",
            "Iteration: 483000 , Mean_loss: 5.9243653e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.861084\n",
            "Iteration: 484000 , Mean_loss: 6.1215515e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85948\n",
            "Iteration: 485000 , Mean_loss: 6.4004225e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85564\n",
            "Iteration: 486000 , Mean_loss: 6.2037925e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85788\n",
            "Iteration: 487000 , Mean_loss: 6.293836e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85645\n",
            "Iteration: 488000 , Mean_loss: 5.5173464e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8656\n",
            "Iteration: 489000 , Mean_loss: 6.5777613e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85597\n",
            "Iteration: 490000 , Mean_loss: 6.28013e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85668\n",
            "Iteration: 491000 , Mean_loss: 5.869215e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86203\n",
            "Iteration: 492000 , Mean_loss: 5.805031e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85993\n",
            "Iteration: 493000 , Mean_loss: 6.008116e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86047\n",
            "Iteration: 494000 , Mean_loss: 6.005131e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85922\n",
            "Iteration: 495000 , Mean_loss: 6.4692827e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.856544\n",
            "Iteration: 496000 , Mean_loss: 6.5359686e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8532\n",
            "Iteration: 497000 , Mean_loss: 5.918679e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85991\n",
            "Iteration: 498000 , Mean_loss: 6.0497314e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85909\n",
            "Iteration: 499000 , Mean_loss: 6.0499474e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8592\n",
            "Iteration: 500000 , Mean_loss: 6.4821998e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85565\n",
            "Iteration: 501000 , Mean_loss: 5.8426376e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.862015\n",
            "Iteration: 502000 , Mean_loss: 6.3591515e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.856575\n",
            "Iteration: 503000 , Mean_loss: 5.85452e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.860855\n",
            "Iteration: 504000 , Mean_loss: 6.220674e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.858116\n",
            "Iteration: 505000 , Mean_loss: 6.7583833e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.853645\n",
            "Iteration: 506000 , Mean_loss: 5.4786738e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.864975\n",
            "Iteration: 507000 , Mean_loss: 6.155931e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8574\n",
            "Iteration: 508000 , Mean_loss: 5.31663e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.865234\n",
            "Iteration: 509000 , Mean_loss: 5.773043e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86185\n",
            "Iteration: 510000 , Mean_loss: 6.126459e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85945\n",
            "Iteration: 511000 , Mean_loss: 5.8093638e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86168\n",
            "Iteration: 512000 , Mean_loss: 5.841284e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.861565\n",
            "Iteration: 513000 , Mean_loss: 6.574928e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85369\n",
            "Iteration: 514000 , Mean_loss: 5.7548114e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86229\n",
            "Iteration: 515000 , Mean_loss: 5.9505187e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86108\n",
            "Iteration: 516000 , Mean_loss: 6.020203e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.859825\n",
            "Iteration: 517000 , Mean_loss: 5.730936e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86428\n",
            "Iteration: 518000 , Mean_loss: 5.782359e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.862114\n",
            "Iteration: 519000 , Mean_loss: 6.032184e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85975\n",
            "Iteration: 520000 , Mean_loss: 5.62907e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86537\n",
            "Iteration: 521000 , Mean_loss: 6.2867375e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.856316\n",
            "Iteration: 522000 , Mean_loss: 6.5244058e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85462\n",
            "Iteration: 523000 , Mean_loss: 6.624414e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8531\n",
            "Iteration: 524000 , Mean_loss: 5.5708015e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.864525\n",
            "Iteration: 525000 , Mean_loss: 6.6299717e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85527\n",
            "Iteration: 526000 , Mean_loss: 5.9781055e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86021\n",
            "Iteration: 527000 , Mean_loss: 7.0315027e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85228\n",
            "Iteration: 528000 , Mean_loss: 5.396552e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.864365\n",
            "Iteration: 529000 , Mean_loss: 6.3338366e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85516\n",
            "Iteration: 530000 , Mean_loss: 6.2609556e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.857346\n",
            "Iteration: 531000 , Mean_loss: 5.408253e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.865135\n",
            "Iteration: 532000 , Mean_loss: 6.035434e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86008\n",
            "Iteration: 533000 , Mean_loss: 5.9057784e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85975\n",
            "Iteration: 534000 , Mean_loss: 6.152462e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85796\n",
            "Iteration: 535000 , Mean_loss: 5.9619433e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.859634\n",
            "Iteration: 536000 , Mean_loss: 6.4729034e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.856895\n",
            "Iteration: 537000 , Mean_loss: 5.5256014e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86378\n",
            "Iteration: 538000 , Mean_loss: 6.598466e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85296\n",
            "Iteration: 539000 , Mean_loss: 5.47508e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86635\n",
            "Iteration: 540000 , Mean_loss: 6.603809e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85477\n",
            "Iteration: 541000 , Mean_loss: 7.096809e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.850716\n",
            "Iteration: 542000 , Mean_loss: 6.3306247e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8564\n",
            "Iteration: 543000 , Mean_loss: 6.9553353e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.851974\n",
            "Iteration: 544000 , Mean_loss: 6.001468e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85923\n",
            "Iteration: 545000 , Mean_loss: 6.0818847e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85955\n",
            "Iteration: 546000 , Mean_loss: 5.757516e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86197\n",
            "Iteration: 547000 , Mean_loss: 6.90615e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85097\n",
            "Iteration: 548000 , Mean_loss: 6.329757e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85435\n",
            "Iteration: 549000 , Mean_loss: 6.0949565e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85865\n",
            "Iteration: 550000 , Mean_loss: 6.0746534e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.859505\n",
            "Iteration: 551000 , Mean_loss: 6.4366536e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85606\n",
            "Iteration: 552000 , Mean_loss: 6.3764605e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85589\n",
            "Iteration: 553000 , Mean_loss: 6.1459396e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85848\n",
            "Iteration: 554000 , Mean_loss: 6.788776e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.852936\n",
            "Iteration: 555000 , Mean_loss: 6.093406e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85956\n",
            "Iteration: 556000 , Mean_loss: 5.985285e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85958\n",
            "Iteration: 557000 , Mean_loss: 5.671548e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86258\n",
            "Iteration: 558000 , Mean_loss: 5.375662e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86638\n",
            "Iteration: 559000 , Mean_loss: 6.5753084e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85312\n",
            "Iteration: 560000 , Mean_loss: 6.1549e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85718\n",
            "Iteration: 561000 , Mean_loss: 5.6629074e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.863235\n",
            "Iteration: 562000 , Mean_loss: 6.571674e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8536\n",
            "Iteration: 563000 , Mean_loss: 5.9168133e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86047\n",
            "Iteration: 564000 , Mean_loss: 6.495772e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85486\n",
            "Iteration: 565000 , Mean_loss: 6.1154224e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.857666\n",
            "Iteration: 566000 , Mean_loss: 6.4366072e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85673\n",
            "Iteration: 567000 , Mean_loss: 6.2923245e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85678\n",
            "Iteration: 568000 , Mean_loss: 6.0016323e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85916\n",
            "Iteration: 569000 , Mean_loss: 6.105636e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85861\n",
            "Iteration: 570000 , Mean_loss: 6.050036e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.859344\n",
            "Iteration: 571000 , Mean_loss: 5.660124e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86282\n",
            "Iteration: 572000 , Mean_loss: 6.871347e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85329\n",
            "Iteration: 573000 , Mean_loss: 6.1209003e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85877\n",
            "Iteration: 574000 , Mean_loss: 6.055141e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85979\n",
            "Iteration: 575000 , Mean_loss: 6.3976254e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85675\n",
            "Iteration: 576000 , Mean_loss: 6.2821496e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85612\n",
            "Iteration: 577000 , Mean_loss: 5.9913696e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.862114\n",
            "Iteration: 578000 , Mean_loss: 6.5865042e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85409\n",
            "Iteration: 579000 , Mean_loss: 5.703044e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86225\n",
            "Iteration: 580000 , Mean_loss: 6.296553e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85696\n",
            "Iteration: 581000 , Mean_loss: 6.056597e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85872\n",
            "Iteration: 582000 , Mean_loss: 6.2543927e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.858864\n",
            "Iteration: 583000 , Mean_loss: 6.3297293e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.856804\n",
            "Iteration: 584000 , Mean_loss: 6.2347167e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86057\n",
            "Iteration: 585000 , Mean_loss: 6.2315366e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85806\n",
            "Iteration: 586000 , Mean_loss: 5.7136517e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86255\n",
            "Iteration: 587000 , Mean_loss: 5.690804e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86226\n",
            "Iteration: 588000 , Mean_loss: 7.0631254e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85377\n",
            "Iteration: 589000 , Mean_loss: 5.9685453e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85971\n",
            "Iteration: 590000 , Mean_loss: 6.529469e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85523\n",
            "Iteration: 591000 , Mean_loss: 5.815851e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86233\n",
            "Iteration: 592000 , Mean_loss: 7.2731773e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.84802\n",
            "Iteration: 593000 , Mean_loss: 5.9273725e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86042\n",
            "Iteration: 594000 , Mean_loss: 5.694985e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.863205\n",
            "Iteration: 595000 , Mean_loss: 6.1151727e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.859116\n",
            "Iteration: 596000 , Mean_loss: 5.8156943e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86271\n",
            "Iteration: 597000 , Mean_loss: 6.3234856e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.8574\n",
            "Iteration: 598000 , Mean_loss: 5.9507215e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.85811\n",
            "Iteration: 599000 , Mean_loss: 5.512142e-06 , Learning rate: 1e-06 , Mean accuracy (%): 99.86437\n",
            "Iteration: 600000 , Mean_loss: 5.9565928e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86253\n",
            "Iteration: 601000 , Mean_loss: 1.1320642e-05 , Learning rate: 8e-07 , Mean accuracy (%): 99.85878\n",
            "Iteration: 602000 , Mean_loss: 5.7666407e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.864044\n",
            "Iteration: 603000 , Mean_loss: 5.6683034e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86391\n",
            "Iteration: 604000 , Mean_loss: 6.915471e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85334\n",
            "Iteration: 605000 , Mean_loss: 6.190437e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.857605\n",
            "Iteration: 606000 , Mean_loss: 5.919182e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86173\n",
            "Iteration: 607000 , Mean_loss: 6.160838e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.859886\n",
            "Iteration: 608000 , Mean_loss: 6.3378848e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.857735\n",
            "Iteration: 609000 , Mean_loss: 6.115917e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.860405\n",
            "Iteration: 610000 , Mean_loss: 5.8549967e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.863335\n",
            "Iteration: 611000 , Mean_loss: 6.5093586e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8547\n",
            "Iteration: 612000 , Mean_loss: 8.328169e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.84568\n",
            "Iteration: 613000 , Mean_loss: 5.8929436e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86222\n",
            "Iteration: 614000 , Mean_loss: 5.6936287e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86246\n",
            "Iteration: 615000 , Mean_loss: 6.5369472e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85578\n",
            "Iteration: 616000 , Mean_loss: 6.4120813e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85494\n",
            "Iteration: 617000 , Mean_loss: 6.279502e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.858215\n",
            "Iteration: 618000 , Mean_loss: 6.521385e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85592\n",
            "Iteration: 619000 , Mean_loss: 5.990196e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85978\n",
            "Iteration: 620000 , Mean_loss: 6.0711486e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8609\n",
            "Iteration: 621000 , Mean_loss: 6.2093472e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85841\n",
            "Iteration: 622000 , Mean_loss: 5.471309e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86545\n",
            "Iteration: 623000 , Mean_loss: 6.7062465e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8535\n",
            "Iteration: 624000 , Mean_loss: 6.4552823e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.855896\n",
            "Iteration: 625000 , Mean_loss: 6.0616467e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86132\n",
            "Iteration: 626000 , Mean_loss: 6.0430075e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86046\n",
            "Iteration: 627000 , Mean_loss: 5.9341473e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86238\n",
            "Iteration: 628000 , Mean_loss: 5.9113586e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85952\n",
            "Iteration: 629000 , Mean_loss: 5.9637287e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.859276\n",
            "Iteration: 630000 , Mean_loss: 6.217316e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85729\n",
            "Iteration: 631000 , Mean_loss: 6.517238e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85721\n",
            "Iteration: 632000 , Mean_loss: 5.9412923e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86069\n",
            "Iteration: 633000 , Mean_loss: 6.1418395e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85805\n",
            "Iteration: 634000 , Mean_loss: 5.8153846e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86121\n",
            "Iteration: 635000 , Mean_loss: 6.147415e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.857994\n",
            "Iteration: 636000 , Mean_loss: 5.4970615e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.864235\n",
            "Iteration: 637000 , Mean_loss: 5.8456885e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86096\n",
            "Iteration: 638000 , Mean_loss: 6.1751784e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85695\n",
            "Iteration: 639000 , Mean_loss: 5.689669e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86267\n",
            "Iteration: 640000 , Mean_loss: 5.8053297e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86378\n",
            "Iteration: 641000 , Mean_loss: 6.6062958e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85374\n",
            "Iteration: 642000 , Mean_loss: 6.6170014e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.852684\n",
            "Iteration: 643000 , Mean_loss: 6.6202274e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85751\n",
            "Iteration: 644000 , Mean_loss: 5.6920585e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8628\n",
            "Iteration: 645000 , Mean_loss: 5.654715e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86293\n",
            "Iteration: 646000 , Mean_loss: 6.28064e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85756\n",
            "Iteration: 647000 , Mean_loss: 5.9844783e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86024\n",
            "Iteration: 648000 , Mean_loss: 6.0420343e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85837\n",
            "Iteration: 649000 , Mean_loss: 6.0656985e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85934\n",
            "Iteration: 650000 , Mean_loss: 6.1323026e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.858864\n",
            "Iteration: 651000 , Mean_loss: 5.97265e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85977\n",
            "Iteration: 652000 , Mean_loss: 5.944869e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8606\n",
            "Iteration: 653000 , Mean_loss: 5.964174e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.862045\n",
            "Iteration: 654000 , Mean_loss: 6.469487e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85545\n",
            "Iteration: 655000 , Mean_loss: 6.3201196e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85638\n",
            "Iteration: 656000 , Mean_loss: 6.4640244e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.856\n",
            "Iteration: 657000 , Mean_loss: 6.2571853e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85922\n",
            "Iteration: 658000 , Mean_loss: 6.1988458e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86064\n",
            "Iteration: 659000 , Mean_loss: 6.427038e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85583\n",
            "Iteration: 660000 , Mean_loss: 5.74752e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86013\n",
            "Iteration: 661000 , Mean_loss: 5.7101042e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86173\n",
            "Iteration: 662000 , Mean_loss: 6.2234703e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85892\n",
            "Iteration: 663000 , Mean_loss: 6.2530007e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85863\n",
            "Iteration: 664000 , Mean_loss: 7.131596e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.850685\n",
            "Iteration: 665000 , Mean_loss: 5.6646572e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.864426\n",
            "Iteration: 666000 , Mean_loss: 6.6402436e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85517\n",
            "Iteration: 667000 , Mean_loss: 5.8223013e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86302\n",
            "Iteration: 668000 , Mean_loss: 6.3338657e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85558\n",
            "Iteration: 669000 , Mean_loss: 6.4961378e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85688\n",
            "Iteration: 670000 , Mean_loss: 5.785794e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86469\n",
            "Iteration: 671000 , Mean_loss: 6.7539104e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85486\n",
            "Iteration: 672000 , Mean_loss: 5.7379116e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86271\n",
            "Iteration: 673000 , Mean_loss: 6.636559e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85365\n",
            "Iteration: 674000 , Mean_loss: 6.7002948e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8541\n",
            "Iteration: 675000 , Mean_loss: 5.6873796e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86481\n",
            "Iteration: 676000 , Mean_loss: 6.6345424e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.855034\n",
            "Iteration: 677000 , Mean_loss: 5.643749e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86413\n",
            "Iteration: 678000 , Mean_loss: 6.1875176e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85788\n",
            "Iteration: 679000 , Mean_loss: 6.0380926e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86124\n",
            "Iteration: 680000 , Mean_loss: 6.294111e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85723\n",
            "Iteration: 681000 , Mean_loss: 6.488306e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.856636\n",
            "Iteration: 682000 , Mean_loss: 6.5955583e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85732\n",
            "Iteration: 683000 , Mean_loss: 6.112763e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85791\n",
            "Iteration: 684000 , Mean_loss: 6.397851e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85846\n",
            "Iteration: 685000 , Mean_loss: 5.849787e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86083\n",
            "Iteration: 686000 , Mean_loss: 5.9775357e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85926\n",
            "Iteration: 687000 , Mean_loss: 6.199929e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.858315\n",
            "Iteration: 688000 , Mean_loss: 5.820626e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.860985\n",
            "Iteration: 689000 , Mean_loss: 6.479099e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.855515\n",
            "Iteration: 690000 , Mean_loss: 5.971773e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86151\n",
            "Iteration: 691000 , Mean_loss: 5.211518e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86684\n",
            "Iteration: 692000 , Mean_loss: 6.521601e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85657\n",
            "Iteration: 693000 , Mean_loss: 6.795085e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.850555\n",
            "Iteration: 694000 , Mean_loss: 6.174436e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.858406\n",
            "Iteration: 695000 , Mean_loss: 6.4937185e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85631\n",
            "Iteration: 696000 , Mean_loss: 6.6814973e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85237\n",
            "Iteration: 697000 , Mean_loss: 6.8718523e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.853516\n",
            "Iteration: 698000 , Mean_loss: 5.7602456e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86185\n",
            "Iteration: 699000 , Mean_loss: 7.072988e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8507\n",
            "Iteration: 700000 , Mean_loss: 5.5390997e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.863914\n",
            "Iteration: 701000 , Mean_loss: 6.967129e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85058\n",
            "Iteration: 702000 , Mean_loss: 5.2681567e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.865364\n",
            "Iteration: 703000 , Mean_loss: 6.6073558e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.853745\n",
            "Iteration: 704000 , Mean_loss: 6.2653507e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.856895\n",
            "Iteration: 705000 , Mean_loss: 6.00875e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.859604\n",
            "Iteration: 706000 , Mean_loss: 6.2334866e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85619\n",
            "Iteration: 707000 , Mean_loss: 6.2919876e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85887\n",
            "Iteration: 708000 , Mean_loss: 7.0714923e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.84901\n",
            "Iteration: 709000 , Mean_loss: 5.782842e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86156\n",
            "Iteration: 710000 , Mean_loss: 6.4838587e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.853935\n",
            "Iteration: 711000 , Mean_loss: 6.123886e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85815\n",
            "Iteration: 712000 , Mean_loss: 5.8576325e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.861336\n",
            "Iteration: 713000 , Mean_loss: 7.0480755e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85072\n",
            "Iteration: 714000 , Mean_loss: 6.0237144e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85784\n",
            "Iteration: 715000 , Mean_loss: 5.5841256e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86415\n",
            "Iteration: 716000 , Mean_loss: 5.9756812e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85998\n",
            "Iteration: 717000 , Mean_loss: 5.8479227e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86006\n",
            "Iteration: 718000 , Mean_loss: 7.1281875e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85044\n",
            "Iteration: 719000 , Mean_loss: 5.3918825e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86601\n",
            "Iteration: 720000 , Mean_loss: 5.8749747e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86189\n",
            "Iteration: 721000 , Mean_loss: 6.391315e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85762\n",
            "Iteration: 722000 , Mean_loss: 5.964251e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85997\n",
            "Iteration: 723000 , Mean_loss: 6.6131124e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85991\n",
            "Iteration: 724000 , Mean_loss: 5.7256907e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.862465\n",
            "Iteration: 725000 , Mean_loss: 6.0194307e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86033\n",
            "Iteration: 726000 , Mean_loss: 6.73847e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85963\n",
            "Iteration: 727000 , Mean_loss: 6.1647133e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85799\n",
            "Iteration: 728000 , Mean_loss: 6.5979e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85505\n",
            "Iteration: 729000 , Mean_loss: 5.888511e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86258\n",
            "Iteration: 730000 , Mean_loss: 6.408867e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85582\n",
            "Iteration: 731000 , Mean_loss: 5.5705577e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.865265\n",
            "Iteration: 732000 , Mean_loss: 5.8165315e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.861145\n",
            "Iteration: 733000 , Mean_loss: 5.5731834e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86389\n",
            "Iteration: 734000 , Mean_loss: 5.932419e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86184\n",
            "Iteration: 735000 , Mean_loss: 6.598524e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85462\n",
            "Iteration: 736000 , Mean_loss: 6.3362054e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85745\n",
            "Iteration: 737000 , Mean_loss: 5.768258e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86437\n",
            "Iteration: 738000 , Mean_loss: 6.5377176e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.852585\n",
            "Iteration: 739000 , Mean_loss: 5.6183435e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86437\n",
            "Iteration: 740000 , Mean_loss: 5.4887946e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86512\n",
            "Iteration: 741000 , Mean_loss: 5.19889e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86716\n",
            "Iteration: 742000 , Mean_loss: 5.768885e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86152\n",
            "Iteration: 743000 , Mean_loss: 5.9293384e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.862495\n",
            "Iteration: 744000 , Mean_loss: 6.2806594e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85689\n",
            "Iteration: 745000 , Mean_loss: 6.59141e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85455\n",
            "Iteration: 746000 , Mean_loss: 5.6977033e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86491\n",
            "Iteration: 747000 , Mean_loss: 5.604716e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86552\n",
            "Iteration: 748000 , Mean_loss: 6.004335e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.860176\n",
            "Iteration: 749000 , Mean_loss: 5.7473408e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86323\n",
            "Iteration: 750000 , Mean_loss: 6.7900583e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.853004\n",
            "Iteration: 751000 , Mean_loss: 5.6692666e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.862274\n",
            "Iteration: 752000 , Mean_loss: 6.1258484e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85771\n",
            "Iteration: 753000 , Mean_loss: 6.073439e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86013\n",
            "Iteration: 754000 , Mean_loss: 5.508451e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86491\n",
            "Iteration: 755000 , Mean_loss: 5.3760623e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86687\n",
            "Iteration: 756000 , Mean_loss: 6.517053e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85503\n",
            "Iteration: 757000 , Mean_loss: 7.0175483e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85538\n",
            "Iteration: 758000 , Mean_loss: 6.2581175e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85858\n",
            "Iteration: 759000 , Mean_loss: 6.312879e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85834\n",
            "Iteration: 760000 , Mean_loss: 6.05083e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.860466\n",
            "Iteration: 761000 , Mean_loss: 5.8611067e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.860565\n",
            "Iteration: 762000 , Mean_loss: 6.3086936e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.857666\n",
            "Iteration: 763000 , Mean_loss: 6.0773873e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86049\n",
            "Iteration: 764000 , Mean_loss: 6.3544135e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.860214\n",
            "Iteration: 765000 , Mean_loss: 5.84784e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86053\n",
            "Iteration: 766000 , Mean_loss: 5.8941405e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86175\n",
            "Iteration: 767000 , Mean_loss: 6.007932e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8621\n",
            "Iteration: 768000 , Mean_loss: 5.549782e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86296\n",
            "Iteration: 769000 , Mean_loss: 6.5129334e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.854294\n",
            "Iteration: 770000 , Mean_loss: 5.75506e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86328\n",
            "Iteration: 771000 , Mean_loss: 5.9465497e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86134\n",
            "Iteration: 772000 , Mean_loss: 6.275199e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8581\n",
            "Iteration: 773000 , Mean_loss: 6.021347e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86049\n",
            "Iteration: 774000 , Mean_loss: 6.0579328e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.860916\n",
            "Iteration: 775000 , Mean_loss: 5.7040124e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86343\n",
            "Iteration: 776000 , Mean_loss: 6.1037663e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86017\n",
            "Iteration: 777000 , Mean_loss: 6.1708556e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.858635\n",
            "Iteration: 778000 , Mean_loss: 5.4544885e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86613\n",
            "Iteration: 779000 , Mean_loss: 6.129687e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.859436\n",
            "Iteration: 780000 , Mean_loss: 6.1869337e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86055\n",
            "Iteration: 781000 , Mean_loss: 6.22045e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.858406\n",
            "Iteration: 782000 , Mean_loss: 6.180714e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85938\n",
            "Iteration: 783000 , Mean_loss: 6.203329e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85745\n",
            "Iteration: 784000 , Mean_loss: 5.8829664e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.862816\n",
            "Iteration: 785000 , Mean_loss: 6.789511e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85424\n",
            "Iteration: 786000 , Mean_loss: 6.4676005e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85723\n",
            "Iteration: 787000 , Mean_loss: 5.881936e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86161\n",
            "Iteration: 788000 , Mean_loss: 6.016506e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86063\n",
            "Iteration: 789000 , Mean_loss: 5.871973e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86518\n",
            "Iteration: 790000 , Mean_loss: 6.4762717e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85703\n",
            "Iteration: 791000 , Mean_loss: 6.262818e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85743\n",
            "Iteration: 792000 , Mean_loss: 5.7202797e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86394\n",
            "Iteration: 793000 , Mean_loss: 6.830306e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85417\n",
            "Iteration: 794000 , Mean_loss: 6.3670236e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.8561\n",
            "Iteration: 795000 , Mean_loss: 6.847257e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85223\n",
            "Iteration: 796000 , Mean_loss: 6.195274e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85828\n",
            "Iteration: 797000 , Mean_loss: 6.127406e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.86037\n",
            "Iteration: 798000 , Mean_loss: 6.387151e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.85663\n",
            "Iteration: 799000 , Mean_loss: 5.703777e-06 , Learning rate: 8e-07 , Mean accuracy (%): 99.862854\n",
            "Iteration: 800000 , Mean_loss: 6.2907084e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85775\n",
            "Iteration: 801000 , Mean_loss: 6.041708e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85897\n",
            "Iteration: 802000 , Mean_loss: 6.0961574e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.859215\n",
            "Iteration: 803000 , Mean_loss: 5.415967e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86633\n",
            "Iteration: 804000 , Mean_loss: 6.717548e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8562\n",
            "Iteration: 805000 , Mean_loss: 5.8940705e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86224\n",
            "Iteration: 806000 , Mean_loss: 6.925269e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85184\n",
            "Iteration: 807000 , Mean_loss: 6.2921763e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85607\n",
            "Iteration: 808000 , Mean_loss: 6.0760813e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86103\n",
            "Iteration: 809000 , Mean_loss: 5.8831756e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86238\n",
            "Iteration: 810000 , Mean_loss: 6.184179e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8587\n",
            "Iteration: 811000 , Mean_loss: 6.0427774e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86039\n",
            "Iteration: 812000 , Mean_loss: 6.685669e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85427\n",
            "Iteration: 813000 , Mean_loss: 6.4569513e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85653\n",
            "Iteration: 814000 , Mean_loss: 5.5268897e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864975\n",
            "Iteration: 815000 , Mean_loss: 6.122128e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86109\n",
            "Iteration: 816000 , Mean_loss: 6.0990988e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85949\n",
            "Iteration: 817000 , Mean_loss: 6.8827867e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85204\n",
            "Iteration: 818000 , Mean_loss: 5.9463027e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8601\n",
            "Iteration: 819000 , Mean_loss: 5.9205076e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86256\n",
            "Iteration: 820000 , Mean_loss: 5.8649075e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.862015\n",
            "Iteration: 821000 , Mean_loss: 5.8743317e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8628\n",
            "Iteration: 822000 , Mean_loss: 5.7985626e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86336\n",
            "Iteration: 823000 , Mean_loss: 5.816372e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86271\n",
            "Iteration: 824000 , Mean_loss: 5.7232355e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86511\n",
            "Iteration: 825000 , Mean_loss: 6.629087e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85427\n",
            "Iteration: 826000 , Mean_loss: 5.888931e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8624\n",
            "Iteration: 827000 , Mean_loss: 6.394311e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8574\n",
            "Iteration: 828000 , Mean_loss: 5.8438413e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.862\n",
            "Iteration: 829000 , Mean_loss: 6.530618e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85827\n",
            "Iteration: 830000 , Mean_loss: 5.5287373e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86544\n",
            "Iteration: 831000 , Mean_loss: 5.8633623e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85997\n",
            "Iteration: 832000 , Mean_loss: 5.747929e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86316\n",
            "Iteration: 833000 , Mean_loss: 5.4300567e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86576\n",
            "Iteration: 834000 , Mean_loss: 6.1012224e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86184\n",
            "Iteration: 835000 , Mean_loss: 6.07227e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.860886\n",
            "Iteration: 836000 , Mean_loss: 5.173878e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.869225\n",
            "Iteration: 837000 , Mean_loss: 5.7318407e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86233\n",
            "Iteration: 838000 , Mean_loss: 6.2024255e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85881\n",
            "Iteration: 839000 , Mean_loss: 5.943328e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86165\n",
            "Iteration: 840000 , Mean_loss: 6.4722517e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85501\n",
            "Iteration: 841000 , Mean_loss: 5.9605936e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86089\n",
            "Iteration: 842000 , Mean_loss: 5.797361e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.862656\n",
            "Iteration: 843000 , Mean_loss: 6.073278e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.859474\n",
            "Iteration: 844000 , Mean_loss: 5.36003e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.867676\n",
            "Iteration: 845000 , Mean_loss: 5.3140493e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86784\n",
            "Iteration: 846000 , Mean_loss: 6.0183083e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85986\n",
            "Iteration: 847000 , Mean_loss: 5.7239067e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.862434\n",
            "Iteration: 848000 , Mean_loss: 6.6093608e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85591\n",
            "Iteration: 849000 , Mean_loss: 6.552038e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.855934\n",
            "Iteration: 850000 , Mean_loss: 5.7773627e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.861946\n",
            "Iteration: 851000 , Mean_loss: 5.937777e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86031\n",
            "Iteration: 852000 , Mean_loss: 6.114741e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.858894\n",
            "Iteration: 853000 , Mean_loss: 6.511762e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8552\n",
            "Iteration: 854000 , Mean_loss: 5.623353e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864975\n",
            "Iteration: 855000 , Mean_loss: 6.2500317e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85952\n",
            "Iteration: 856000 , Mean_loss: 6.473031e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.857635\n",
            "Iteration: 857000 , Mean_loss: 6.209486e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85977\n",
            "Iteration: 858000 , Mean_loss: 6.8722507e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8531\n",
            "Iteration: 859000 , Mean_loss: 6.2001654e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.858475\n",
            "Iteration: 860000 , Mean_loss: 5.956405e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.861404\n",
            "Iteration: 861000 , Mean_loss: 6.5781473e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85516\n",
            "Iteration: 862000 , Mean_loss: 6.008529e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8608\n",
            "Iteration: 863000 , Mean_loss: 6.3120638e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85848\n",
            "Iteration: 864000 , Mean_loss: 5.6870927e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86248\n",
            "Iteration: 865000 , Mean_loss: 5.546239e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864006\n",
            "Iteration: 866000 , Mean_loss: 6.155862e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8585\n",
            "Iteration: 867000 , Mean_loss: 5.844371e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864235\n",
            "Iteration: 868000 , Mean_loss: 6.195708e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85847\n",
            "Iteration: 869000 , Mean_loss: 5.077151e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.87\n",
            "Iteration: 870000 , Mean_loss: 5.8309765e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86173\n",
            "Iteration: 871000 , Mean_loss: 5.8796113e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86019\n",
            "Iteration: 872000 , Mean_loss: 6.04868e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.860695\n",
            "Iteration: 873000 , Mean_loss: 5.962381e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86203\n",
            "Iteration: 874000 , Mean_loss: 6.3468697e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85687\n",
            "Iteration: 875000 , Mean_loss: 5.8835535e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86229\n",
            "Iteration: 876000 , Mean_loss: 6.2206036e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85933\n",
            "Iteration: 877000 , Mean_loss: 6.013377e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8607\n",
            "Iteration: 878000 , Mean_loss: 6.329152e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85988\n",
            "Iteration: 879000 , Mean_loss: 5.5724013e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86535\n",
            "Iteration: 880000 , Mean_loss: 5.726767e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86543\n",
            "Iteration: 881000 , Mean_loss: 6.262687e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85754\n",
            "Iteration: 882000 , Mean_loss: 6.5318673e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85421\n",
            "Iteration: 883000 , Mean_loss: 5.7737243e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86277\n",
            "Iteration: 884000 , Mean_loss: 6.5766335e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85546\n",
            "Iteration: 885000 , Mean_loss: 5.910214e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86236\n",
            "Iteration: 886000 , Mean_loss: 5.897693e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86175\n",
            "Iteration: 887000 , Mean_loss: 6.1925643e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85907\n",
            "Iteration: 888000 , Mean_loss: 5.6307217e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86459\n",
            "Iteration: 889000 , Mean_loss: 6.3315056e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8553\n",
            "Iteration: 890000 , Mean_loss: 6.3136654e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.858025\n",
            "Iteration: 891000 , Mean_loss: 6.038963e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86098\n",
            "Iteration: 892000 , Mean_loss: 5.462245e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86529\n",
            "Iteration: 893000 , Mean_loss: 6.1284773e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85945\n",
            "Iteration: 894000 , Mean_loss: 5.9255894e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86336\n",
            "Iteration: 895000 , Mean_loss: 5.8219193e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864044\n",
            "Iteration: 896000 , Mean_loss: 6.9534617e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.853035\n",
            "Iteration: 897000 , Mean_loss: 5.631391e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86495\n",
            "Iteration: 898000 , Mean_loss: 7.227392e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.848595\n",
            "Iteration: 899000 , Mean_loss: 6.4075693e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.856636\n",
            "Iteration: 900000 , Mean_loss: 6.2171803e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.860115\n",
            "Iteration: 901000 , Mean_loss: 6.032254e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86201\n",
            "Iteration: 902000 , Mean_loss: 5.921085e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86115\n",
            "Iteration: 903000 , Mean_loss: 5.8899586e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.860275\n",
            "Iteration: 904000 , Mean_loss: 5.896326e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86232\n",
            "Iteration: 905000 , Mean_loss: 5.9956037e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86069\n",
            "Iteration: 906000 , Mean_loss: 5.664181e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86403\n",
            "Iteration: 907000 , Mean_loss: 6.346179e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.858734\n",
            "Iteration: 908000 , Mean_loss: 5.610471e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86571\n",
            "Iteration: 909000 , Mean_loss: 5.714847e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.863625\n",
            "Iteration: 910000 , Mean_loss: 5.633828e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86596\n",
            "Iteration: 911000 , Mean_loss: 6.70723e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.855156\n",
            "Iteration: 912000 , Mean_loss: 5.729243e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86496\n",
            "Iteration: 913000 , Mean_loss: 5.011848e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.87067\n",
            "Iteration: 914000 , Mean_loss: 6.817211e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85351\n",
            "Iteration: 915000 , Mean_loss: 6.391332e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8573\n",
            "Iteration: 916000 , Mean_loss: 5.495638e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86479\n",
            "Iteration: 917000 , Mean_loss: 6.089056e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.860725\n",
            "Iteration: 918000 , Mean_loss: 6.2228646e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85884\n",
            "Iteration: 919000 , Mean_loss: 6.19184e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85896\n",
            "Iteration: 920000 , Mean_loss: 6.2324857e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86009\n",
            "Iteration: 921000 , Mean_loss: 5.55364e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86531\n",
            "Iteration: 922000 , Mean_loss: 5.663349e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864456\n",
            "Iteration: 923000 , Mean_loss: 5.1371885e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8699\n",
            "Iteration: 924000 , Mean_loss: 6.5748704e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.855576\n",
            "Iteration: 925000 , Mean_loss: 6.1321325e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8595\n",
            "Iteration: 926000 , Mean_loss: 6.4093956e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.858025\n",
            "Iteration: 927000 , Mean_loss: 6.3539414e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85745\n",
            "Iteration: 928000 , Mean_loss: 6.045629e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8604\n",
            "Iteration: 929000 , Mean_loss: 5.907178e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86279\n",
            "Iteration: 930000 , Mean_loss: 5.121523e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.87016\n",
            "Iteration: 931000 , Mean_loss: 6.0728157e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86083\n",
            "Iteration: 932000 , Mean_loss: 5.4539523e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86472\n",
            "Iteration: 933000 , Mean_loss: 7.1364884e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85042\n",
            "Iteration: 934000 , Mean_loss: 5.911903e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8616\n",
            "Iteration: 935000 , Mean_loss: 6.0117536e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86102\n",
            "Iteration: 936000 , Mean_loss: 5.791879e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.863365\n",
            "Iteration: 937000 , Mean_loss: 5.2698147e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8677\n",
            "Iteration: 938000 , Mean_loss: 6.301455e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85891\n",
            "Iteration: 939000 , Mean_loss: 5.119761e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86916\n",
            "Iteration: 940000 , Mean_loss: 5.8153264e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86239\n",
            "Iteration: 941000 , Mean_loss: 5.664824e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864555\n",
            "Iteration: 942000 , Mean_loss: 5.464475e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.867294\n",
            "Iteration: 943000 , Mean_loss: 6.173977e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85875\n",
            "Iteration: 944000 , Mean_loss: 6.429983e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.8572\n",
            "Iteration: 945000 , Mean_loss: 5.710576e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86376\n",
            "Iteration: 946000 , Mean_loss: 5.6851286e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86245\n",
            "Iteration: 947000 , Mean_loss: 9.036225e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86189\n",
            "Iteration: 948000 , Mean_loss: 5.5033192e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.866776\n",
            "Iteration: 949000 , Mean_loss: 6.464611e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.856255\n",
            "Iteration: 950000 , Mean_loss: 6.2965555e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85846\n",
            "Iteration: 951000 , Mean_loss: 5.999369e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86187\n",
            "Iteration: 952000 , Mean_loss: 6.219703e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.858864\n",
            "Iteration: 953000 , Mean_loss: 6.056064e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86006\n",
            "Iteration: 954000 , Mean_loss: 5.4403963e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86491\n",
            "Iteration: 955000 , Mean_loss: 5.2852088e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.867966\n",
            "Iteration: 956000 , Mean_loss: 5.692396e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86384\n",
            "Iteration: 957000 , Mean_loss: 6.2941904e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85722\n",
            "Iteration: 958000 , Mean_loss: 5.5331543e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86585\n",
            "Iteration: 959000 , Mean_loss: 6.316879e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85791\n",
            "Iteration: 960000 , Mean_loss: 5.166201e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86908\n",
            "Iteration: 961000 , Mean_loss: 6.890556e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.853004\n",
            "Iteration: 962000 , Mean_loss: 6.149883e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85792\n",
            "Iteration: 963000 , Mean_loss: 6.2954623e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.858475\n",
            "Iteration: 964000 , Mean_loss: 6.1590263e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85718\n",
            "Iteration: 965000 , Mean_loss: 5.4507514e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86567\n",
            "Iteration: 966000 , Mean_loss: 5.625673e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86624\n",
            "Iteration: 967000 , Mean_loss: 6.179311e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85945\n",
            "Iteration: 968000 , Mean_loss: 5.685988e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86394\n",
            "Iteration: 969000 , Mean_loss: 5.289422e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.868706\n",
            "Iteration: 970000 , Mean_loss: 5.0917656e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.868996\n",
            "Iteration: 971000 , Mean_loss: 5.778639e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86343\n",
            "Iteration: 972000 , Mean_loss: 6.160046e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.859314\n",
            "Iteration: 973000 , Mean_loss: 6.186336e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.857864\n",
            "Iteration: 974000 , Mean_loss: 5.6971876e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86326\n",
            "Iteration: 975000 , Mean_loss: 5.682009e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.863556\n",
            "Iteration: 976000 , Mean_loss: 5.8622604e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86455\n",
            "Iteration: 977000 , Mean_loss: 5.71502e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86513\n",
            "Iteration: 978000 , Mean_loss: 6.0321745e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86105\n",
            "Iteration: 979000 , Mean_loss: 6.065281e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85838\n",
            "Iteration: 980000 , Mean_loss: 5.7348107e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86383\n",
            "Iteration: 981000 , Mean_loss: 5.4330485e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86583\n",
            "Iteration: 982000 , Mean_loss: 6.302247e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85618\n",
            "Iteration: 983000 , Mean_loss: 6.1771716e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85968\n",
            "Iteration: 984000 , Mean_loss: 7.0591973e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.850334\n",
            "Iteration: 985000 , Mean_loss: 6.429963e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85598\n",
            "Iteration: 986000 , Mean_loss: 5.0523067e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.870636\n",
            "Iteration: 987000 , Mean_loss: 6.61904e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85579\n",
            "Iteration: 988000 , Mean_loss: 6.900752e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85303\n",
            "Iteration: 989000 , Mean_loss: 5.655751e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86373\n",
            "Iteration: 990000 , Mean_loss: 6.033433e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85955\n",
            "Iteration: 991000 , Mean_loss: 5.9039767e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86188\n",
            "Iteration: 992000 , Mean_loss: 6.33785e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85844\n",
            "Iteration: 993000 , Mean_loss: 5.9600598e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.860504\n",
            "Iteration: 994000 , Mean_loss: 5.777042e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.864075\n",
            "Iteration: 995000 , Mean_loss: 6.93688e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85251\n",
            "Iteration: 996000 , Mean_loss: 6.140486e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85955\n",
            "Iteration: 997000 , Mean_loss: 6.109006e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.859406\n",
            "Iteration: 998000 , Mean_loss: 5.929359e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86291\n",
            "Iteration: 999000 , Mean_loss: 6.6462094e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.85548\n",
            "Iteration: 1000000 , Mean_loss: 5.7159714e-06 , Learning rate: 4e-07 , Mean accuracy (%): 99.86444\n",
            "Maximum accuracy attained in training: 99.87067\n"
          ]
        }
      ],
      "source": [
        "# Run Experiment\n",
        "params, optim, nn_policy, mean_losses, mean_accuracy = run_experiment(ProdNetRbc_pretrain(), config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "jaxDEQN minimal.ipynb",
      "provenance": [],
      "mount_file_id": "1QW4LOfJ21C_dgXh3C3UXHawi1YgzYTjE",
      "authorship_tag": "ABX9TyNqVSYXh9gx3da0n3bYZI9k",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}